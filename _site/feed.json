{
    "version": "https://jsonfeed.org/version/1",
    "title": "Scattered Unoriginal",
    "home_page_url": "http://localhost:4000/",
    "feed_url": "http://localhost:4000/feed.json",
    "description": null,
    "icon": "http://localhost:4000/apple-touch-icon.png",
    "favicon": "http://localhost:4000/favicon.ico",
    "expired": false,
    
    "author":  {
        "name": "Christopher Lin",
        "url": null,
        "avatar": null
    },
    
"items": [
    
        {
            "id": "http://localhost:4000/2021/07/05/hyperion",
            "title": "Johnny vs. Johnny",
            "summary": null,
            "content_text": "Spoilers ahead for Hyperion and Johnny MnemonicIt is always surprising to me when science fiction or fantasy authors reveal themselves to be reactionaries. It’s true that many SFF writers fall into the category of milquetoast neoliberal; even William Gibson, for all his radical transhumanist writings, has become a Trump reply-guying, Russiagate-pushing bore these days. However, true reactionaries like Orson Scott Card and Terry Goodkind are much rarer. It seems strange to me that someone who makes a living of imagining and empathazing with radical alterity can come to the conclusions that they do.Dan Simmons is one of these reactionary SFF writers, a fact that I was unaware of when I began reading his 1989 magnum opus, Hyperion. Hyperion is a space opera of epic scale and ambitions. Structured after the Canterbury Tales, it tells the story of pilgrims from the Hegemony of Man as they travel to the Time Tombs of Hyperion. The Tombs are a mysterious artifact of unknown origin, travelling backwards through time for incomprehensible reasons. Guarding it is the fearsome Shrike, a god-like being of metal and cybernetics, who impales its victims alive on its “Tree of Pain”. As the novel progresses, each pilgrim tells a tale about their relationship to Hyperion, in the process revealing various aspects of Hegemony society and posing philosophical conundrums.It’s a thought provoking read, with some genuinely beautiful passages and an admirably panoramic sweep. Which makes it a far, far cry from what Simmons has been producing in the past decade. His 2011 novel Flashback is a detective story set in a dystopic near-future America, where the Obama administration’s foreign policy failures coupled with the country’s culture of entitlement has led to the collapse of the US. A Muslim “Global Caliphate” has nuked Israel and now is hell bent on destroying America. In short, he wrote a lengthier version of what your racist uncle periodically sends out in chain emails.So what changed? Perhaps the lazy impulse would be to say that nothing has changed and to re-examine his older works with a suspicious eye, trying to detect proto-fascist themes even in his best work. This is exactly the strategy I’m going to adopt because, well, it’s just fun to do. Whether it’s lazy or true is up to you to.I think the best way to think about what Simmons is doing in Hyperion is to take a comparative approach: what themes were present in other successful 80s SF works? What, if anything, is Simmons responding to? Where does he diverge in thought?The Detectives Tale, the fifth tale in the novel, is an excellent entry point, because it is, to put it kindly, a blatant pastiche of William Gibson’s work, in particular the story Johnny Mnemonic. The similarities are almost too numerous to count: both are set in a cyberpunk urban landscape, both adopt a neo-hardboiled voice, both feature a major character named Johnny, both Johnnys drive the plot because of a cybernetic alteration, both follow a badass female character as they try to protect Johnny. Simmons even tries to throw a lampshade on it by mentioning offhand a character named “Cowboy Gibson”.In Johnny Mnemonic, the point of view character is Johnny, a man with a memory chip implanted in his brain. He makes a living transporting sensitive data in his implant, which he himself does not have access to. (We’ll leave the Freudian implications of this alone for now.) After obtaining some sensitive data from the Yakuza, he decides to go rogue and sell the data himself. He enlists the protection of Molly Millions, a sex-worker-turned-cyborg-bodyguard to protect him, and the pair navigate a series of escalating perils before finding safety with a group calling themselves the Lo-Teks, a liminal gang of body-modification loving technophobes.It’s a plot structure that reappears over and over in Gibson’s work from the 80’s and 90’s, one that very much defines cyberpunk as a genre. Marginal characters (which map directly onto the marginalized in our current society) find themselves in some situation where they have the opportunity to improve their material conditions by taking from those in power. They build a coalition with other disparate marginal figures and they take on Power, which usually exists as hegemonic criminal empires or megacorporations. Whether or not they succeed in the end, their actions are a small act of rebellion, drawn from a multitude united by their differences and discontent. It’s this radical dynamic that led Mark Fisher to conclude that cyberpunk was the last real literary movement before the total subsumption of culture under Capitalist Realism.In The Detective’s Tale, the dynamics are reversed, even while keeping the same cyberpunk trappings. The point of view character is not the one seeking protection but rather the one providing it. Brawne Lamia is a detective, written with various tongue-in-cheek references to Raymond Chandler. Notably, she is not the scrappy, working-class detective out of Chandler, but rather a high-ranking senator’s daughter who decided to pursue a life of adventure. She is hired by a man named Johnny to solve his own murder — it turns out that Johnny is a “cybrid”, a half-human, half-AI construct and thus cannot be fully killed by bodily death. Even more intriguing, it turns out that Johnny’s consciousness is a reconstruction of the Romantic era poet John Keats. (Keats and Romantic literature have a big role to play in Hyperion, but I’ll get to that later.)It turns out that the AIs, which live in a deep space apart from the humans, created Johnny in order to understand the nature of the Time Tombs, and now a faction of them want him dead. (I’ll spare you all the lore and plot convolutions.) After a series of pulse-pounding adventures, Brawne and Johnny fall in love and decide to escape together to Hyperion. Johnny decides to fully vest his consciousness into his body, destroying the parts of his AI self that cannot be contained in his brain, and essentially becoming completely human. You can probably guess what happens from there.Rather than Gibson’s vision of the marginal disrupting the center, here the opposite occurs. Brawne, a child of privilege who chooses to maintain those powerful connections, takes Johnny, a liminal being caught between humanity and non-humanity, under her guardianship. It is only through the protection of her power that the pair survive, and in the end, Johnny resolves his conflict by completely destroying the part of him which is other than human. In contrast to Gibson’s posthumanism, The Detective’s Tale reaffirms an ethical superiority in being human.I would argue that this extends to the entire novel in general. Simmons’ political project in Hyperion is to create a vision of humanity, one that is based solely on dominant Western culture. As I mentioned before, John Keats is the main literary reference point of the novel; it’s even implied that it is the influence of Keats’ verse that brings the Shrike into existence and sets in motion the events of the novel. In The Pilgrim’s Tale, the poet Martin Silenus tells of his education in the “classics” — it is very interesting to note that most of the Western classic texts mentioned are real, while the Eastern classics are wholly fictional, seeming to imply that Simmons does not regard any existing Eastern literature to be worthy of propagating among the stars.To his credit, Simmons does try to temper this conservatism through the figure of the Ousters, humans who chose to break away from the Hegemony of Man and continue evolving in deep space. They are the boogeymen of the universe, dark savages who threaten the very existence of humanity as it exists in the Hegemony. However, in The Consul’s Tale, it is revealed that they are actually benevolent and are the true next step in humanity’s evolution. Through some quick Wikipedia readings, it seems that they become increasingly important in the sequels and ultimately become the saviors of Man.Still, I don’t think that this compensates for the Eurocentric humanism that is built into the very structure of Hyperion. And as much as he may proclaim the Ousters’ benevolence, Simmons is unable to imagine or empathize with any characters outside of the boundaries of Western (largely bourgeois) subjectivity. The main characters are: 1. a Catholic priest 2. a Hegemony military commander 3. an aristocractic poet 4. a professor 5. above mentioned detective and 6. an imperial consul. It would be quite a stretch to say that any of these hail from the margins of society, or even that they require any effort from the reader to imagine alterity.I do think that Simmons is a master writer and storyteller. I was so gripped by The Priest’s Tale that I skipped out on several hours of work just to finish it as quickly as possible. However, I suspect that he is a poor writer of science fiction. Unable to imagine otherness, he instead chooses to project the values of 80’s American middle-class society into the future, granting them the status of immortal truths about mankind.It’s easy to see how someone who was already predisposed to this line of thinking in the 80’s could easily become a reactionary in the 2010’s. Islam, as a challenge to the hegemony of Western value systems, becomes an affront to humanity itself. Progressivism is seen as degeneracy. It’s a path that many intellectuals of yesteryear seem to have taken since 2015, the Richard Dawkinses and the Sam Harrises of the world.Again, I’m just trying to string together breadcrumbs here to make a nice story. I’m sure that Simmons is far more complicated than I could ever imagine. I’m sure that he did not write Hyperion to be a conservative manifesto. But I do think it’s worthwhile to reexamine the work of the people who once thought of themselves as liberals but in the years since have revealed themselves to hold ideas that are anything but liberal.",
            "content_html": "<p><em>Spoilers ahead for Hyperion and Johnny Mnemonic</em></p><p>It is always surprising to me when science fiction or fantasy authors reveal themselves to be reactionaries. It’s true that many SFF writers fall into the category of milquetoast neoliberal; even William Gibson, for all his radical transhumanist writings, has become a Trump reply-guying, Russiagate-pushing bore these days. However, true reactionaries like Orson Scott Card and Terry Goodkind are much rarer. It seems strange to me that someone who makes a living of imagining and empathazing with radical alterity can come to the conclusions that they do.</p><p>Dan Simmons is one of these reactionary SFF writers, a fact that I was unaware of when I began reading his 1989 magnum opus, <em>Hyperion</em>. <em>Hyperion</em> is a space opera of epic scale and ambitions. Structured after the Canterbury Tales, it tells the story of pilgrims from the Hegemony of Man as they travel to the Time Tombs of Hyperion. The Tombs are a mysterious artifact of unknown origin, travelling backwards through time for incomprehensible reasons. Guarding it is the fearsome Shrike, a god-like being of metal and cybernetics, who impales its victims alive on its “Tree of Pain”. As the novel progresses, each pilgrim tells a tale about their relationship to Hyperion, in the process revealing various aspects of Hegemony society and posing philosophical conundrums.</p><p>It’s a thought provoking read, with some genuinely beautiful passages and an admirably panoramic sweep. Which makes it a far, far cry from what Simmons has been producing in the past decade. His 2011 novel <em>Flashback</em> is a detective story set in a dystopic near-future America, where the Obama administration’s foreign policy failures coupled with the country’s culture of entitlement has led to the collapse of the US. A Muslim “Global Caliphate” has nuked Israel and now is hell bent on destroying America. In short, he wrote a lengthier version of what your racist uncle periodically sends out in chain emails.</p><p>So what changed? Perhaps the lazy impulse would be to say that nothing has changed and to re-examine his older works with a suspicious eye, trying to detect proto-fascist themes even in his best work. This is exactly the strategy I’m going to adopt because, well, it’s just fun to do. Whether it’s lazy or true is up to you to.</p><p>I think the best way to think about what Simmons is doing in <em>Hyperion</em> is to take a comparative approach: what themes were present in other successful 80s SF works? What, if anything, is Simmons responding to? Where does he diverge in thought?</p><p><em>The Detectives Tale</em>, the fifth tale in the novel, is an excellent entry point, because it is, to put it kindly, a blatant pastiche of William Gibson’s work, in particular the story <em>Johnny Mnemonic</em>. The similarities are almost too numerous to count: both are set in a cyberpunk urban landscape, both adopt a neo-hardboiled voice, both feature a major character named Johnny, both Johnnys drive the plot because of a cybernetic alteration, both follow a badass female character as they try to protect Johnny. Simmons even tries to throw a lampshade on it by mentioning offhand a character named “Cowboy Gibson”.</p><p>In <em>Johnny Mnemonic</em>, the point of view character is Johnny, a man with a memory chip implanted in his brain. He makes a living transporting sensitive data in his implant, which he himself does not have access to. (We’ll leave the Freudian implications of this alone for now.) After obtaining some sensitive data from the Yakuza, he decides to go rogue and sell the data himself. He enlists the protection of Molly Millions, a sex-worker-turned-cyborg-bodyguard to protect him, and the pair navigate a series of escalating perils before finding safety with a group calling themselves the Lo-Teks, a liminal gang of body-modification loving technophobes.</p><p>It’s a plot structure that reappears over and over in Gibson’s work from the 80’s and 90’s, one that very much defines cyberpunk as a genre. Marginal characters (which map directly onto the marginalized in our current society) find themselves in some situation where they have the opportunity to improve their material conditions by taking from those in power. They build a coalition with other disparate marginal figures and they take on Power, which usually exists as hegemonic criminal empires or megacorporations. Whether or not they succeed in the end, their actions are a small act of rebellion, drawn from a multitude united by their differences and discontent. It’s this radical dynamic that led Mark Fisher to conclude that cyberpunk was the last real literary movement before the total subsumption of culture under Capitalist Realism.</p><p>In <em>The Detective’s Tale</em>, the dynamics are reversed, even while keeping the same cyberpunk trappings. The point of view character is not the one seeking protection but rather the one providing it. Brawne Lamia is a detective, written with various tongue-in-cheek references to Raymond Chandler. Notably, she is not the scrappy, working-class detective out of Chandler, but rather a high-ranking senator’s daughter who decided to pursue a life of adventure. She is hired by a man named Johnny to solve his own murder — it turns out that Johnny is a “cybrid”, a half-human, half-AI construct and thus cannot be fully killed by bodily death. Even more intriguing, it turns out that Johnny’s consciousness is a reconstruction of the Romantic era poet John Keats. (Keats and Romantic literature have a big role to play in Hyperion, but I’ll get to that later.)</p><p>It turns out that the AIs, which live in a deep space apart from the humans, created Johnny in order to understand the nature of the Time Tombs, and now a faction of them want him dead. (I’ll spare you all the lore and plot convolutions.) After a series of pulse-pounding adventures, Brawne and Johnny fall in love and decide to escape together to Hyperion. Johnny decides to fully vest his consciousness into his body, destroying the parts of his AI self that cannot be contained in his brain, and essentially becoming completely human. You can probably guess what happens from there.</p><p>Rather than Gibson’s vision of the marginal disrupting the center, here the opposite occurs. Brawne, a child of privilege who chooses to maintain those powerful connections, takes Johnny, a liminal being caught between humanity and non-humanity, under her guardianship. It is only through the protection of her power that the pair survive, and in the end, Johnny resolves his conflict by completely destroying the part of him which is other than human. In contrast to Gibson’s posthumanism, <em>The Detective’s Tale</em> reaffirms an ethical superiority in being human.</p><p>I would argue that this extends to the entire novel in general. Simmons’ political project in <em>Hyperion</em> is to create a vision of humanity, one that is based solely on dominant Western culture. As I mentioned before, John Keats is the main literary reference point of the novel; it’s even implied that it is the influence of Keats’ verse that brings the Shrike into existence and sets in motion the events of the novel. In <em>The Pilgrim’s Tale</em>, the poet Martin Silenus tells of his education in the “classics” — it is very interesting to note that most of the Western classic texts mentioned are real, while the Eastern classics are wholly fictional, seeming to imply that Simmons does not regard any existing Eastern literature to be worthy of propagating among the stars.</p><p>To his credit, Simmons does try to temper this conservatism through the figure of the Ousters, humans who chose to break away from the Hegemony of Man and continue evolving in deep space. They are the boogeymen of the universe, dark savages who threaten the very existence of humanity as it exists in the Hegemony. However, in <em>The Consul’s Tale</em>, it is revealed that they are actually benevolent and are the true next step in humanity’s evolution. Through some quick Wikipedia readings, it seems that they become increasingly important in the sequels and ultimately become the saviors of Man.</p><p>Still, I don’t think that this compensates for the Eurocentric humanism that is built into the very structure of Hyperion. And as much as he may proclaim the Ousters’ benevolence, Simmons is unable to imagine or empathize with any characters outside of the boundaries of Western (largely bourgeois) subjectivity. The main characters are: 1. a Catholic priest 2. a Hegemony military commander 3. an aristocractic poet 4. a professor 5. above mentioned detective and 6. an imperial consul. It would be quite a stretch to say that any of these hail from the margins of society, or even that they require any effort from the reader to imagine alterity.</p><p>I do think that Simmons is a master writer and storyteller. I was so gripped by <em>The Priest’s Tale</em> that I skipped out on several hours of work just to finish it as quickly as possible. However, I suspect that he is a poor writer of science fiction. Unable to imagine otherness, he instead chooses to project the values of 80’s American middle-class society into the future, granting them the status of immortal truths about mankind.</p><p>It’s easy to see how someone who was already predisposed to this line of thinking in the 80’s could easily become a reactionary in the 2010’s. Islam, as a challenge to the hegemony of Western value systems, becomes an affront to humanity itself. Progressivism is seen as degeneracy. It’s a path that many intellectuals of yesteryear seem to have taken since 2015, the Richard Dawkinses and the Sam Harrises of the world.</p><p>Again, I’m just trying to string together breadcrumbs here to make a nice story. I’m sure that Simmons is far more complicated than I could ever imagine. I’m sure that he did not write <em>Hyperion</em> to be a conservative manifesto. But I do think it’s worthwhile to reexamine the work of the people who once thought of themselves as liberals but in the years since have revealed themselves to hold ideas that are anything but liberal.</p>",
            "url": "http://localhost:4000/2021/07/05/hyperion",
            
            
            
            "tags": ["essay","literature"],
            
            "date_published": "2021-07-05T15:00:00+00:00",
            "date_modified": "2021-07-05T15:00:00+00:00",
            
                "author":  {
                "name": "Christopher Lin",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "http://localhost:4000/2021/01/01/dynamic-functional-connectivity-with-julia",
            "title": "Dynamic Functional Connectivity with Julia",
            "summary": null,
            "content_text": "At the Center for Brain Circuit Therapeutics, almost all of our computational research revolves around functional connectivity analysis of resting-state functional MRI (rsfMRI). While there are many subtleties in the preprocessing of rsfMRI and the interpretation of functional connectivity, but the short version of our primary analysis is:  Extract a representative timecourse for the region of interest (ROI)  Correlate that representative timecourse to every voxel in the brainWith &gt;200k voxels in a 2mm resolution brain volume and 1000 brains to process for each region of interest, this amounts to quite a lot of Pearson correlations. When I joined the lab, this was being done with a Matlab script that parallelized across ROIs, which could process approximately 1 ROI every 10 minutes. I rewrote the pipeline using Python with Numba JIT acceleration, which, with some math trickery, brought the processing time to about 30 seconds per ROI.While this is probably as fast as this particular analysis method is going to get without some sort of GPU optimization, I was always bothered by how much effort it took to create that Python application. For example, the only way to calculate the Pearson correlation between two vectors is to use scipy.stats.pearsonr(); Numpy only provides numpy.corrcoef() which can only produce whole correlation matrices. As I quickly discovered, pearsonr() is not a particularly performant function, partially because it calculates the p-value of the correlation in addition to the r-value, a behavior that cannot be turned off. Perhaps I’m just not a particularly competent programmer, but I also struggled to use nunmpy.apply_along_axis() to try to vectorize it. In the end, I had to manually compute the Pearson correlation using its dot-product form and basic Numpy methods.That wasn’t the end of my problems; I wanted to use Numba to optimize the computationally heavy parts of the code. It turns out that the promise of being able to wrap everything in @jit is a bit more complicated than it seems. Certain Numpy functions aren’t supported (e.g. numpy.mean(axis=1)). I suppose where I went wrong was that I applied the Numba decorators after the bulk of the code had been finished, which meant that I had to rethink and rewrite the unsupported parts, while what I should have done is started with the optimizations in the first place.All these little problems aggregated to the effect that the tools that I had created were quite inflexible. In fact, I don’t think that I’ve since reused any of it for similar tasks other than slight modifications to the exact same functional connectivity analysis. And so, when I started reading about Julia, I began to feel the familiar, impulsive itch to jump shit to yet another different language.Julia is a dynamic, JIT compiled language geared toward scientific/numerical computing, which promises the speed of native C while using a high-level Python-like syntax. Additionally, distributed and GPU computing are built in by default with the GPUArray type and the distributed package. With lofty promises like that, it’s hard to see how anyone wouldn’t be intrigued at the least.I decided that dynamic functional connectivity analysis might be a good test case for me to try out the language. Dynamic connectivity is a technique that hasn’t been well explored in our lab yet; the idea is to take sliding-window chunks out of a resting state timecourse and analyze how connectivity patterns change over the course of a scan. While this does raise the noise floor quite a bit, the hope is that it can capture slower, oscilatory patterns or trends.",
            "content_html": "<p>At the Center for Brain Circuit Therapeutics, almost all of our computational research revolves around functional connectivity analysis of resting-state functional MRI (rsfMRI). While there are many subtleties in the preprocessing of rsfMRI and the interpretation of functional connectivity, but the short version of our primary analysis is:</p><ol>  <li>Extract a representative timecourse for the region of interest (ROI)</li>  <li>Correlate that representative timecourse to every voxel in the brain</li></ol><p><img src=\"/assets/connectivity.png\" alt=\"connectivity diagram\" /></p><p>With &gt;200k voxels in a 2mm resolution brain volume and 1000 brains to process for each region of interest, this amounts to quite a lot of Pearson correlations. When I joined the lab, this was being done with a Matlab script that parallelized across ROIs, which could process approximately 1 ROI every 10 minutes. I rewrote the pipeline using Python with Numba JIT acceleration, which, with some math trickery, brought the processing time to about 30 seconds per ROI.</p><p>While this is probably as fast as this particular analysis method is going to get without some sort of GPU optimization, I was always bothered by how much effort it took to create that Python application. For example, the only way to calculate the Pearson correlation between two vectors is to use <code class=\"language-plaintext highlighter-rouge\">scipy.stats.pearsonr()</code>; Numpy only provides <code class=\"language-plaintext highlighter-rouge\">numpy.corrcoef()</code> which can <em>only</em> produce whole correlation matrices. As I quickly discovered, <code class=\"language-plaintext highlighter-rouge\">pearsonr()</code> is not a particularly performant function, partially because it calculates the p-value of the correlation in addition to the r-value, a behavior that cannot be turned off. Perhaps I’m just not a particularly competent programmer, but I also struggled to use <code class=\"language-plaintext highlighter-rouge\">nunmpy.apply_along_axis()</code> to try to vectorize it. In the end, I had to manually compute the Pearson correlation using its dot-product form and basic Numpy methods.</p><p>That wasn’t the end of my problems; I wanted to use Numba to optimize the computationally heavy parts of the code. It turns out that the promise of being able to wrap everything in <code class=\"language-plaintext highlighter-rouge\">@jit</code> is a bit more complicated than it seems. Certain Numpy functions aren’t supported (e.g. <code class=\"language-plaintext highlighter-rouge\">numpy.mean(axis=1)</code>). I suppose where I went wrong was that I applied the Numba decorators after the bulk of the code had been finished, which meant that I had to rethink and rewrite the unsupported parts, while what I should have done is started with the optimizations in the first place.</p><p>All these little problems aggregated to the effect that the tools that I had created were quite inflexible. In fact, I don’t think that I’ve since reused any of it for similar tasks other than slight modifications to the exact same functional connectivity analysis. And so, when I started reading about Julia, I began to feel the familiar, impulsive itch to jump shit to yet another different language.</p><p><a href=\"https://julialang.org/\">Julia</a> is a dynamic, JIT compiled language geared toward scientific/numerical computing, which promises the speed of native C while using a high-level Python-like syntax. Additionally, distributed and GPU computing are built in by default with the <code class=\"language-plaintext highlighter-rouge\">GPUArray</code> type and the <code class=\"language-plaintext highlighter-rouge\">distributed</code> package. With lofty promises like that, it’s hard to see how anyone wouldn’t be intrigued at the least.</p><p>I decided that dynamic functional connectivity analysis might be a good test case for me to try out the language. Dynamic connectivity is a technique that hasn’t been well explored in our lab yet; the idea is to take sliding-window chunks out of a resting state timecourse and analyze how connectivity patterns change over the course of a scan. While this does raise the noise floor quite a bit, the hope is that it can capture slower, oscilatory patterns or trends.</p>",
            "url": "http://localhost:4000/2021/01/01/dynamic-functional-connectivity-with-julia",
            
            
            
            
            
            "date_published": "2021-01-01T05:00:00+00:00",
            "date_modified": "2021-01-01T05:00:00+00:00",
            
                "author":  {
                "name": "Christopher Lin",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "http://localhost:4000/2020/12/13/photography",
            "title": "Further Reflections on Photography",
            "summary": null,
            "content_text": "      In the past half year or so, I have immersed myself more deeply in the art of photography than ever before. A lucky acquisition of a flatbed scanner from Craigslist meant that I could develop and scan photos all from the comfort of my own studio apartment. (The onset of the pandemic had put a temporary halt to my photography, as the Harvard library, which I relied on for its scanners, had shut down for the foreseeable future.) Now that I was able to shoot a roll of film during the day and see the results that very evening, I was more motivated than ever to explore the art of photography rather than simply photographic technique.    Internet forums are unfortunately a poor place for finding such discussion. Just like guitar forums are more concerned with tonewoods and amplifier circuits than dynamics and phrasing, photography forums are replete with information on the optical characteristics of lenses, but lack discussion on how to make use of them. Some suggested that the best way to improve was to study photos from master photographers, much like how a studious jazz musician learns classic solos by heart. However, I have yet to find exactly how one is supposed to study a photograph — do you simply stare at it until it’s burned into the back of your retinas?    Others suggested that the way to improve photographs is to study composition rules from painting. It seemed to me like a reasonable way to learn, but it also feels like taking advice on writing a novel from a screenwriting handbook. Both are forms of textual storytelling (the raw screenplay at least), but the way that the two mediums interact with audiences are vastly different — a screenplay must be able to be consumed in a two hour session, while a novel could be something the reader lives with for months, spending devoted evenings together like lovers. Structuring a novel like a screenplay would be selling short everything a novel is capable of accomplishing. The essence of the novel is precisely in the moments of quiet and digression that any competent screenwriter would immediately slash from the text.    Similarly, there is a categorical difference between the mediums of painting and photograph. There is good reason why the pictorialists of the early 20th century, who tried to elevate photography by attempting to make photographs more like painting, lost out to the tack-sharp landscapes of Ansel Adams. But of what that difference was exactly, I could not say. I am, after all, both a novice photographer and a novice consumer of photographs. Outside of advertising, the only photographs that I am regularly in contact with are from social media feeds, which hardly warrant serious study. In fact, I have noticed that most of the aesthetics that I try to recreate in photography are drawn from cinema, another related but wholly different medium. Thus began my recent readings and ponderings on photography.        To me, the first and most intuitive understanding of photographic technology is as a form of externalized memory. In Marshall McLuhan’s terms, photography would be an extension of human capacities; just as the wheel extends the foot in speed and distance, the photograph extends the capacities of memory in duration, fidelity and distribution. It could be argued that the lens is an extension of the eye, but I would categorize that more as “optics” rather than “photography”. Indeed, what the camera sees through the lens is (almost) always reflected into the eye, so that what is recorded on film or sensor is still an object of memory.    This is the quotidian usage of the photograph, intensified by the infinite number of photos we can now take from our phones. We no longer need to memorize a wifi password, shopping list, or PowerPoint slide; the photograph has replaced that function of memory. When we take a snapshot of friends at a party, the purpose is never aesthetic, but solely for the purpose of remembrance at a later time. When these photos eventually make their way to social media, the only people for whom they will hold any significance are the people who were present at the time of taking; it is a way of distributing memory among a group. It’s telling that when social media sites show you old photos, they’re referred to not as “photos” but as “memories”.        For me, photographs function as a trigger for memory as well as a store of memory. Contrary to the common phenomenon of “source amnesia”, viewing a photo often brings back not just the scene being framed, but also the experience of taking the image. This is especially true of photos taken with film SLRs; the act of carefully framing, focusing and metering seems to cement these moments in my mind.    So it seems that photography holds an intimate connection with memory. And of course when discussing memory, we cannot help but notice the flitting spectre of death at the corners of our vision.        Walter Benjamin makes a distinction between the “ritual value” and “exhibition value” of pieces of art. The exhibition value of art is based on public exposure to the work; the more widely a work is consumed, the more it is valued. In contrast, the ritual value is based upon scarcity and secrecy, like the stolen masterpiece hidden away in a private collector’s home. With the advent of photographic reproduction, Benjamin was optimistic that the exhibition value would fully replace the ritual value of art, rendering the work of art to the proletarian masses rather than being held hostage by the bourgeoisie.    However, Benjamin identified one area of photography that was still dominated by ritual value: portraiture. The portrait photograph belonged solely in the realm of the ritual, what he terms the “Cult of Remembrance”.  Like the Victorian practice of keeping locks of hair from the dead, the portrait photograph is an attempt to hold on to a departed soul. The candid portrait is perhaps the most explicit example of this. In attempting to capture the “natural” micro-expressions of the face, the candid portrait tries to grasp something of the transcendental subject. And in accordance with the ritual use of art, candid photos usually stay safely and secretly on our phone camera rolls.        In fact, there is an almost direct analogy between photography and the practice of taking death masks in the 19th and early 20th centuries. Just as the mold is in a direct physical relationship with the face of the corpse, so too are the grains of film in a direct chemical relationship with the subject. Both form a negative image which bears little resemblance to the original, but with which a likeness of the original can be recreated via casting or printing. As Marcia Pointon notes, while the mold of a death mask is in dialogue with the corpse, the cast is in dialogue only with abstract curves. This poses a problem for our conception of the photograph as a store of memory: the photographic print is already secondhand.    Unlike the death mask, photography is able to be reproduced infinitely. With every duplication of the cast, the death mask loses resolution, while the film negative will hold its form indefinitely. Perhaps this is the full realization of the Victorian dream, especially if we consider the term “death” loosely: death as simply the permanent absence of people, things, places, and times. Now, more than ever, we have opened up the doors and windows for ghosts to stream in, ghosts not of those that have passed, but ghosts of likenesses.        Roland Barthes also links the portrait photograph to death, but for different reasons. In Camera Lucida, Barthes poses that having a photo taken is like experiencing a “micro-death”. The subject is instantly collapsed into an object, analogous to the reduction of the subject to corpse in death. In fact, the moment that the subject of a photograph knows they are being photographed and adopts a pose, the micro-death has already occurred; in that instant, the subject has already viewed themselves as object.    This puts a disturbing spin on scrolling through your Instagram feed. Discourse on so-called “selfie culture” has been beaten to a bloody pulp, but I don’t think I have read any analysis of the phenomenon not as an expression of narcissism, but as an expression of the terror of death. I think that it’s uncontroversial to note that American culture has a particularly unhealthy relationship with aging and death. This is often framed as America sweeping death under the rug and refusing to acknowledge its possibility, but perhaps the exact opposite is true: American culture is death obsessed. The compulsive taking of portraits and usage of social media is not from a place of vanity but from the fear of being forgotten. If I distribute my likeness and share my thoughts as widely as possible, then physical death will not be the end of me. And if I have a photograph of you, I will still possess you even after you leave forever. The rituals of the Cult of Remembrance have become one and the same as the rituals of modern American culture.        Concomitant to my renewed enthusiasm for photography was the brief revival of a doomed relationship. The first time we met again, we spread out a picnic blanket in the center of the Common. We were both unprepared for the autumn chill that had just begun to creep in, I, in my office clothes with only a raincoat, and she in a striped summer dress with only a thin cotton jacket for warmth.    I know this with precision because I had brought my camera that day, had recorded it all on Kodak Tri-X 400 speed film, push-processed to 1600 ISO to account for the waning light. I had tried to catch her on her way to a smile, eyes glancing up and to the right, a classic candid portrait, but had mistimed the shot so that instead her mouth is open in a look of semi-surprise. (Later, when I showed her the photo, she apologized for being unphotogenic, and I apologized for being a poor photographer.) I had asked her to take a photo of me as well. I showed her how to read the light meter, set the shutter speed and aperture, and pull the focus. But she had missed the focus entirely, and I appeared as nothing but a faded smear of gray.        To reduce photography to memory and death still feels unsatisfactory. There is something in the photograph that is in excess of memory, and this reduction also neglects the fact that there is often a mismatch between what is remembered and what is represented in the photograph. The camera focuses on the wrong object, the subject is not in frame, a pedestrian passes in front of the lens. This is completely antithetical to the way that memory operates; we almost never remember what we are not trying to pay attention to.    Barthes calls these accidents the punctum, which are opposed to the studium. The studium is the intellectual subject of the photograph, say, a subway train. The studium is coded by social and linguistic structures; I cannot take a photo of a subway train without being implicitly in dialogue with all other photos that have been taken of subway trains, as well as all paintings of subway trains, all videos of subway trains and all books that mention subway trains. In contrast, the punctum is that which breaks through the domination of the studium. The punctum is the unexpectable, the uncontrollable, like if a pigeon were to flash its wing across the frame right as I took it. This immediately separates the photograph from the painting. The painting (the more classical form at least) is all studium; every brush stroke is considered by the artist, filtered by the rules of culture and the language of painting.        Barthes’ distinction between the punctum and the studium is reminiscent of Jacques Lacan’s division of subjectivity into the Imaginary, the Symbolic, and the Real. The Imaginary consists of the ego and its projections; this is what we experience as quotidian reality. The Symbolic are the sociolinguistic structures that shape what can and cannot be experienced. Finally, the Real is that which cannot be captured within the Symbolic and Imaginary registers.    Thus, the studium belongs to the Symbolic and the Imaginary, while the punctum belongs to the Real. Memory is strictly bounded by the Symbolic and Imaginary, and this is the essential difference between memory and photography. Memory cannot freeze a bird in flight or retain minute details. On the other hand, the photograph, in its ability to capture and represent the uncontrollable and un-experiencable, is a way to make contact with the Real.        Very recently, I decided to start developing color film in addition to black-and-white. I had always been scared off by the need to control water temperatures precisely, but I realized that a few rolls of poorly developed film were a small price to pay for a new mode of expression.    Roland Barthes was distrustful of the reality of color images. He said of them, “For me, color is an artifice, a cosmetic (like the kind used to paint corpses).” This seems like an unfair characterization to me; although the physics and chemistry involved in forming a color photograph is more complex, the underlying mechanisms are the same. In fact, I would argue that color photography is more real than black-and-white, and by that I mean that it is more Real. By capturing the extra dimension of color, there emerges a new field of operation from which the punctum may appear.    I recently took a photograph of a subway platform. I was near the end of the roll after a journey to Carson Beach in South Boston. I have a habit of rushing through the last few frames in a roll, impatient to develop the film and see what I did and did not capture. Thus, the last five or so frames are always meandering photos of chance, often subjectless snapshots of wherever I might have found myself. Before the platform photo, I had captured stairs, girders, the railway tracks looking out from a high window. I expected the platform photo — a train approaching headlong and a woman in a beige coat facing it — to be rather trite, given the exhausted subject matter. However, when I developed the frame later that evening, I found something unexpected, a punctum if you will: the red paint of the train and the red of the signs correspond perfectly with the woman’s red hat (which I had not noticed in the moment), forming a triangular kinship in the center of the frame.        Barthes closes his book with an exploration of photographs of his recently deceased mother and takes solace in their undeniable reality. His mother was once a girl, once a young woman, once a new mother; she lived, and the photographs are proof. For him, that is the true value of the photograph. It is undeniable proof that things existed and that events happened. It is not disturbing that photographs and memory are mismatched; in fact, there is no stronger evidence that a photograph is incontrovertible proof than the touch of the Real.    I must admit, I have little experience of real death; my grandparents died far across the ocean, too far away to mourn properly. My closest experiences are with volunteering in a hospice. Those that I met there are surely dead by now, and the very idea of taking a photograph of any of them feels viscerally repulsive. Their ghosts are not mine to possess.    I do, however, have as much experience with permanent absence as anyone else. I had lent her a camera (an automatic point-and-shoot this time) for a hiking trip she was taking with her roommate. She returned it to me the last time I saw her. She had taken seven frames: two too underexposed to be seen, a road sign, a cloud, a building at an intersection, her roommate posing with hands under chin, her face flatly and unnaturally lit by the flash. A handful of flyaways on the back of her head stood on end.  ",
            "content_html": "<ol>  <li>    <p>In the past half year or so, I have immersed myself more deeply in the art of photography than ever before. A lucky acquisition of a flatbed scanner from Craigslist meant that I could develop and scan photos all from the comfort of my own studio apartment. (The onset of the pandemic had put a temporary halt to my photography, as the Harvard library, which I relied on for its scanners, had shut down for the foreseeable future.) Now that I was able to shoot a roll of film during the day and see the results that very evening, I was more motivated than ever to explore the art of photography rather than simply photographic technique.</p>    <p>Internet forums are unfortunately a poor place for finding such discussion. Just like guitar forums are more concerned with tonewoods and amplifier circuits than dynamics and phrasing, photography forums are replete with information on the optical characteristics of lenses, but lack discussion on how to make use of them. Some suggested that the best way to improve was to study photos from master photographers, much like how a studious jazz musician learns classic solos by heart. However, I have yet to find exactly how one is supposed to study a photograph — do you simply stare at it until it’s burned into the back of your retinas?</p>    <p>Others suggested that the way to improve photographs is to study composition rules from painting. It seemed to me like a reasonable way to learn, but it also feels like taking advice on writing a novel from a screenwriting handbook. Both are forms of textual storytelling (the raw screenplay at least), but the way that the two mediums interact with audiences are vastly different — a screenplay must be able to be consumed in a two hour session, while a novel could be something the reader lives with for months, spending devoted evenings together like lovers. Structuring a novel like a screenplay would be selling short everything a novel is capable of accomplishing. The essence of the novel is precisely in the moments of quiet and digression that any competent screenwriter would immediately slash from the text.</p>    <p>Similarly, there is a categorical difference between the mediums of painting and photograph. There is good reason why the pictorialists of the early 20th century, who tried to elevate photography by attempting to make photographs more like painting, lost out to the tack-sharp landscapes of Ansel Adams. But of what that difference was exactly, I could not say. I am, after all, both a novice photographer and a novice consumer of photographs. Outside of advertising, the only photographs that I am regularly in contact with are from social media feeds, which hardly warrant serious study. In fact, I have noticed that most of the aesthetics that I try to recreate in photography are drawn from cinema, another related but wholly different medium. Thus began my recent readings and ponderings on photography.</p>  </li>  <li>    <p>To me, the first and most intuitive understanding of photographic technology is as a form of externalized memory. In Marshall McLuhan’s terms, photography would be an <em>extension</em> of human capacities; just as the wheel extends the foot in speed and distance, the photograph extends the capacities of memory in duration, fidelity and distribution. It could be argued that the lens is an extension of the eye, but I would categorize that more as “optics” rather than “photography”. Indeed, what the camera sees through the lens is (almost) always reflected into the eye, so that what is recorded on film or sensor is still an object of memory.</p>    <p>This is the quotidian usage of the photograph, intensified by the infinite number of photos we can now take from our phones. We no longer need to memorize a wifi password, shopping list, or PowerPoint slide; the photograph has replaced that function of memory. When we take a snapshot of friends at a party, the purpose is never aesthetic, but solely for the purpose of remembrance at a later time. When these photos eventually make their way to social media, the only people for whom they will hold any significance are the people who were present at the time of taking; it is a way of distributing memory among a group. It’s telling that when social media sites show you old photos, they’re referred to not as “photos” but as “memories”.</p>  </li>  <li>    <p>For me, photographs function as a trigger for memory as well as a store of memory. Contrary to the common phenomenon of “source amnesia”, viewing a photo often brings back not just the scene being framed, but also the experience of taking the image. This is especially true of photos taken with film SLRs; the act of carefully framing, focusing and metering seems to cement these moments in my mind.</p>    <p>So it seems that photography holds an intimate connection with memory. And of course when discussing memory, we cannot help but notice the flitting spectre of death at the corners of our vision.</p>  </li>  <li>    <p>Walter Benjamin makes a distinction between the “ritual value” and “exhibition value” of pieces of art. The exhibition value of art is based on public exposure to the work; the more widely a work is consumed, the more it is valued. In contrast, the ritual value is based upon scarcity and secrecy, like the stolen masterpiece hidden away in a private collector’s home. With the advent of photographic reproduction, Benjamin was optimistic that the exhibition value would fully replace the ritual value of art, rendering the work of art to the proletarian masses rather than being held hostage by the bourgeoisie.</p>    <p>However, Benjamin identified one area of photography that was still dominated by ritual value: portraiture. The portrait photograph belonged solely in the realm of the ritual, what he terms the “Cult of Remembrance”.  Like the Victorian practice of keeping locks of hair from the dead, the portrait photograph is an attempt to hold on to a departed soul. The candid portrait is perhaps the most explicit example of this. In attempting to capture the “natural” micro-expressions of the face, the candid portrait tries to grasp something of the transcendental subject. And in accordance with the ritual use of art, candid photos usually stay safely and secretly on our phone camera rolls.</p>  </li>  <li>    <p>In fact, there is an almost direct analogy between photography and the practice of taking death masks in the 19th and early 20th centuries. Just as the mold is in a direct physical relationship with the face of the corpse, so too are the grains of film in a direct chemical relationship with the subject. Both form a negative image which bears little resemblance to the original, but with which a likeness of the original can be recreated via casting or printing. As Marcia Pointon notes, while the mold of a death mask is in dialogue with the corpse, the cast is in dialogue only with abstract curves. This poses a problem for our conception of the photograph as a store of memory: the photographic print is already secondhand.</p>    <p>Unlike the death mask, photography is able to be reproduced infinitely. With every duplication of the cast, the death mask loses resolution, while the film negative will hold its form indefinitely. Perhaps this is the full realization of the Victorian dream, especially if we consider the term “death” loosely: death as simply the permanent absence of people, things, places, and times. Now, more than ever, we have opened up the doors and windows for ghosts to stream in, ghosts not of those that have passed, but ghosts of likenesses.</p>  </li>  <li>    <p>Roland Barthes also links the portrait photograph to death, but for different reasons. In <em>Camera Lucida</em>, Barthes poses that having a photo taken is like experiencing a “micro-death”. The subject is instantly collapsed into an object, analogous to the reduction of the subject to corpse in death. In fact, the moment that the subject of a photograph knows they are being photographed and adopts a pose, the micro-death has already occurred; in that instant, the subject has already viewed themselves as object.</p>    <p>This puts a disturbing spin on scrolling through your Instagram feed. Discourse on so-called “selfie culture” has been beaten to a bloody pulp, but I don’t think I have read any analysis of the phenomenon not as an expression of narcissism, but as an expression of the terror of death. I think that it’s uncontroversial to note that American culture has a particularly unhealthy relationship with aging and death. This is often framed as America sweeping death under the rug and refusing to acknowledge its possibility, but perhaps the exact opposite is true: American culture is death obsessed. The compulsive taking of portraits and usage of social media is not from a place of vanity but from the fear of being forgotten. If I distribute my likeness and share my thoughts as widely as possible, then physical death will not be the end of me. And if I have a photograph of you, I will still possess you even after you leave forever. The rituals of the Cult of Remembrance have become one and the same as the rituals of modern American culture.</p>  </li>  <li>    <p>Concomitant to my renewed enthusiasm for photography was the brief revival of a doomed relationship. The first time we met again, we spread out a picnic blanket in the center of the Common. We were both unprepared for the autumn chill that had just begun to creep in, I, in my office clothes with only a raincoat, and she in a striped summer dress with only a thin cotton jacket for warmth.</p>    <p>I know this with precision because I had brought my camera that day, had recorded it all on Kodak Tri-X 400 speed film, push-processed to 1600 ISO to account for the waning light. I had tried to catch her on her way to a smile, eyes glancing up and to the right, a classic candid portrait, but had mistimed the shot so that instead her mouth is open in a look of semi-surprise. (Later, when I showed her the photo, she apologized for being unphotogenic, and I apologized for being a poor photographer.) I had asked her to take a photo of me as well. I showed her how to read the light meter, set the shutter speed and aperture, and pull the focus. But she had missed the focus entirely, and I appeared as nothing but a faded smear of gray.</p>  </li>  <li>    <p>To reduce photography to memory and death still feels unsatisfactory. There is something in the photograph that is in excess of memory, and this reduction also neglects the fact that there is often a mismatch between what is remembered and what is represented in the photograph. The camera focuses on the wrong object, the subject is not in frame, a pedestrian passes in front of the lens. This is completely antithetical to the way that memory operates; we almost never remember what we are not trying to pay attention to.</p>    <p>Barthes calls these accidents the <em>punctum</em>, which are opposed to the <em>studium</em>. The <em>studium</em> is the intellectual subject of the photograph, say, a subway train. The <em>studium</em> is coded by social and linguistic structures; I cannot take a photo of a subway train without being implicitly in dialogue with all other photos that have been taken of subway trains, as well as all paintings of subway trains, all videos of subway trains and all books that mention subway trains. In contrast, the <em>punctum</em> is that which breaks through the domination of the <em>studium</em>. The <em>punctum</em> is the unexpectable, the uncontrollable, like if a pigeon were to flash its wing across the frame right as I took it. This immediately separates the photograph from the painting. The painting (the more classical form at least) is all <em>studium</em>; every brush stroke is considered by the artist, filtered by the rules of culture and the language of painting.</p>  </li>  <li>    <p>Barthes’ distinction between the <em>punctum</em> and the <em>studium</em> is reminiscent of Jacques Lacan’s division of subjectivity into the Imaginary, the Symbolic, and the Real. The Imaginary consists of the ego and its projections; this is what we experience as quotidian reality. The Symbolic are the sociolinguistic structures that shape what can and cannot be experienced. Finally, the Real is that which cannot be captured within the Symbolic and Imaginary registers.</p>    <p>Thus, the <em>studium</em> belongs to the Symbolic and the Imaginary, while the <em>punctum</em> belongs to the Real. Memory is strictly bounded by the Symbolic and Imaginary, and this is the essential difference between memory and photography. Memory cannot freeze a bird in flight or retain minute details. On the other hand, the photograph, in its ability to capture and represent the uncontrollable and un-experiencable, is a way to make contact with the Real.</p>  </li>  <li>    <p>Very recently, I decided to start developing color film in addition to black-and-white. I had always been scared off by the need to control water temperatures precisely, but I realized that a few rolls of poorly developed film were a small price to pay for a new mode of expression.</p>    <p>Roland Barthes was distrustful of the reality of color images. He said of them, “For me, color is an artifice, a cosmetic (like the kind used to paint corpses).” This seems like an unfair characterization to me; although the physics and chemistry involved in forming a color photograph is more complex, the underlying mechanisms are the same. In fact, I would argue that color photography is <em>more</em> real than black-and-white, and by that I mean that it is more Real. By capturing the extra dimension of color, there emerges a new field of operation from which the <em>punctum</em> may appear.</p>    <p>I recently took a photograph of a subway platform. I was near the end of the roll after a journey to Carson Beach in South Boston. I have a habit of rushing through the last few frames in a roll, impatient to develop the film and see what I did and did not capture. Thus, the last five or so frames are always meandering photos of chance, often subjectless snapshots of wherever I might have found myself. Before the platform photo, I had captured stairs, girders, the railway tracks looking out from a high window. I expected the platform photo — a train approaching headlong and a woman in a beige coat facing it — to be rather trite, given the exhausted subject matter. However, when I developed the frame later that evening, I found something unexpected, a <em>punctum</em> if you will: the red paint of the train and the red of the signs correspond perfectly with the woman’s red hat (which I had not noticed in the moment), forming a triangular kinship in the center of the frame.</p>  </li>  <li>    <p>Barthes closes his book with an exploration of photographs of his recently deceased mother and takes solace in their undeniable reality. His mother was once a girl, once a young woman, once a new mother; she lived, and the photographs are proof. For him, that is the true value of the photograph. It is undeniable proof that things existed and that events happened. It is not disturbing that photographs and memory are mismatched; in fact, there is no stronger evidence that a photograph is incontrovertible proof than the touch of the Real.</p>    <p>I must admit, I have little experience of real death; my grandparents died far across the ocean, too far away to mourn properly. My closest experiences are with volunteering in a hospice. Those that I met there are surely dead by now, and the very idea of taking a photograph of any of them feels viscerally repulsive. Their ghosts are not mine to possess.</p>    <p>I do, however, have as much experience with permanent absence as anyone else. I had lent her a camera (an automatic point-and-shoot this time) for a hiking trip she was taking with her roommate. She returned it to me the last time I saw her. She had taken seven frames: two too underexposed to be seen, a road sign, a cloud, a building at an intersection, her roommate posing with hands under chin, her face flatly and unnaturally lit by the flash. A handful of flyaways on the back of her head stood on end.</p>  </li></ol>",
            "url": "http://localhost:4000/2020/12/13/photography",
            
            
            
            
            
            "date_published": "2020-12-13T05:00:00+00:00",
            "date_modified": "2020-12-13T05:00:00+00:00",
            
                "author":  {
                "name": "Christopher Lin",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "http://localhost:4000/2020/03/22/burrows",
            "title": "Burrows",
            "summary": null,
            "content_text": "You would think that now that the world has come to a halt, I would findmore time to write. But, quite to the contrary, I’ve been having troublereading, let alone writing. It’s near impossible for my mind not towander off after a few pages; the lizard part of my brain deems it muchmore important to ceaselessly track the increasing number of COVID casesthan it is to contemplate the labyrinthine work of Kafka.I certainly haven’t made it easy for myself with my choice of readingmaterial; Kafka’s work oozes with the paranoid, hypochondriac anxietythat I’ve had far too much of in the past days. I’m halfway through TheBurrow, which describes the psychological torture that a burrowinganimal endures, knowing that no matter how carefully concieved andconstructed their home is, the looming dangers of the outside are alwayson the verge of seeping through the cracks. As I wash my hands for thefourteenth time in a day, I can’t help but picture the burrowingcreature slamming their furry head against the earth to form the wallsof their tunnel.The global mandate of social distancing has forced me to confront thesubstance of my own burrow: a bed pushed up into a corner by the window,a decaying office chair, a faux mahogany desk, an electric guitar, and ashelf of unopened books. What exactly is it that I’m building a bulwarkagainst? What sort of den have I made myself? What subterraneancreatures do I think might burst through my floorboards? It seems theunopened books may give the biggest clue.The indictment Kafka makes seems clear. These constructed signifiers ofthe life I’ve attempted to design have themselves become a prison. Ishould leave behind these impositions of modernity and search for theauthentic, unstructured life. As the burrowing creature notes at onepoint, it seems happier to live in an open field of danger than it is tobecome pathologically fixated on certain particular dangers.And yet to take The Burrow as a cautionary tale would seem inappropriatein these times. I live not in a burrow but in a warren, populated bymultitudes. Every person I pass on the street opens up the inside oftheir home to me; a careless gesture on my part could shatter the lifethey have constructed. Thus, to be a hypochondriac is to be noble, andto take hold of life’s pleasures or dangers is to betray the warren.Perhaps that is the true horror of postmodernity: in being connected toeveryone and everything, we become responsible for everyone andeverything. The pursuit of an authentic life in the liberal tradition isno longer possible, if it were ever possible at all.Of course, I don’t yet know how this story ends. From its trajectory, Iwould venture to guess that the last pages will feature the compactedearthen walls collapsing so that the outside rushes ruthlessly inward. Ihope that my instincts are wrong. I’ll keep you updated.",
            "content_html": "<p>You would think that now that the world has come to a halt, I would findmore time to write. But, quite to the contrary, I’ve been having troublereading, let alone writing. It’s near impossible for my mind not towander off after a few pages; the lizard part of my brain deems it muchmore important to ceaselessly track the increasing number of COVID casesthan it is to contemplate the labyrinthine work of Kafka.</p><p>I certainly haven’t made it easy for myself with my choice of readingmaterial; Kafka’s work oozes with the paranoid, hypochondriac anxietythat I’ve had far too much of in the past days. I’m halfway through TheBurrow, which describes the psychological torture that a burrowinganimal endures, knowing that no matter how carefully concieved andconstructed their home is, the looming dangers of the outside are alwayson the verge of seeping through the cracks. As I wash my hands for thefourteenth time in a day, I can’t help but picture the burrowingcreature slamming their furry head against the earth to form the wallsof their tunnel.</p><p>The global mandate of social distancing has forced me to confront thesubstance of my own burrow: a bed pushed up into a corner by the window,a decaying office chair, a faux mahogany desk, an electric guitar, and ashelf of unopened books. What exactly is it that I’m building a bulwarkagainst? What sort of den have I made myself? What subterraneancreatures do I think might burst through my floorboards? It seems theunopened books may give the biggest clue.</p><p>The indictment Kafka makes seems clear. These constructed signifiers ofthe life I’ve attempted to design have themselves become a prison. Ishould leave behind these impositions of modernity and search for theauthentic, unstructured life. As the burrowing creature notes at onepoint, it seems happier to live in an open field of danger than it is tobecome pathologically fixated on certain particular dangers.</p><p>And yet to take The Burrow as a cautionary tale would seem inappropriatein these times. I live not in a burrow but in a warren, populated bymultitudes. Every person I pass on the street opens up the inside oftheir home to me; a careless gesture on my part could shatter the lifethey have constructed. Thus, to be a hypochondriac is to be noble, andto take hold of life’s pleasures or dangers is to betray the warren.Perhaps that is the true horror of postmodernity: in being connected toeveryone and everything, we become responsible for everyone andeverything. The pursuit of an authentic life in the liberal tradition isno longer possible, if it were ever possible at all.</p><p>Of course, I don’t yet know how this story ends. From its trajectory, Iwould venture to guess that the last pages will feature the compactedearthen walls collapsing so that the outside rushes ruthlessly inward. Ihope that my instincts are wrong. I’ll keep you updated.</p>",
            "url": "http://localhost:4000/2020/03/22/burrows",
            
            
            
            
            
            "date_published": "2020-03-22T05:00:00+00:00",
            "date_modified": "2020-03-22T05:00:00+00:00",
            
                "author":  {
                "name": "Christopher Lin",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "http://localhost:4000/2020/01/23/fireworks",
            "title": "Fireworks Over Boston Common",
            "summary": null,
            "content_text": "My sister and her boyfriend visited me over New Year’s. On the day of the eve, after having our fill of window shopping at Newbury Street, we decided on a whim to go see a movie. In the darkness of the theater, we whiled away the afternoon alongside similarly bored Bostonians, and by the time we left the theater at seven, the sky too had darkened to an inky black.“Do you want to go see the fireworks in the park?” she asked me, proposing yet another unplanned activity. I hadn’t even known that such festivities were taking place, much less at this early hour. I suppose it takes someone from out of town to recognize all the things that occur in your own city. (It’s strange how I feel that it’s my city, though I’ve lived here for less than a year. I attribute it to experiencing the city on foot, feeling each crack in the pavement rather than gliding high over the roads in a car.)The website listed the event location cryptically only as “The Ballpark”. I vaguely recalled having wandered past a baseball field in a post- all-you-can-eat-sushi delirium, but had no idea how I would make my way back to it. We decided that the best course of action was to follow the largest crowd of people, trusting that they would take us eventually to the right place.Our faith was misguided though, as the crowd took us instead to the Frog Pond, which in winter is repurposed into a skating rink (I do wonder what becomes of the frogs. Are they transported to a warm and safe place, perhaps close to where the ducks of Central Park are kept? Or do they stare up with crystalline eyes at the blades that pass over their faces?). I had suggested that we go skating earlier in the day, but passing by we saw that the rink was packed, children and adults alike skating round and round counterclockwise, uptempo pop music blaring out from elevated speakers. Watching their fishlike schooling, we lost our appetite for winter sports.“Kevin’s a terrible skater anyways,” my sister told me, “We went once last year and he spent most of the time on his ass. Then someone fell in the rink and dislocated his shoulder, and he almost puked right there on the ice.”She further described the twisted limb with a clinician’s fascinated glee. His face paled at the traumatic memory.But now the rink had been cleared out for some sort of skating show. Instead of summery pop, the speakers were playing a crackly rendition of Tchaikovsky’s Nutcracker. We tried to shoulder our way through the crowd to get a look, but they had planned in advance and were dug in too deeply to move. (Plus, it’s bad form to shove children who barely come up to your elbow.)“Look,” said my sister, who had walked out in front of us, “We can get a pretty good view from up here.”She was on top of a slight incline that let us peek over the tops of rule-abiding heads and into a corner of the rink. Occasionally, a sequined arm would flash into view, or the shadow of a ponytail would splash across the floodlights when the figure skater leapt into the air. The crowd was strangely quiet, enraptured by the lone woman who traced erratic loops across the ice, like a single flake of snow twirling through frigid air.Joining another stream of people, we found ourselves swept to the base of the Soldiers and Sailors Monument. In the darkness, its skyward column seemed sinister, the bronze faces on its side cold and inscrutable. As if in rebellion, teenagers had clambered atop the marble, laughing to each other and sipping from opaque bottles. For a second I felt the urge to join them, to take the sacred stone as my own; after all, it was to be a new decade in a few hours, and in that moment all altars to the past seemed foolish.Instead I joined my sister and Kevin on the grassy hillside. She had located the Ballpark, whose usual fluorescence had been extinguished for the coming show. Couples spread picnic baskets on the frozen ground, not bothering to disguise their bottles of champagne. Strollers were parked sideways as to not plummet down the incline towards the incoming decade.When the fireworks began I was startled by our proximity. We were close enough to hear the muted thumps as each rocket launched out of its tube, whistling unseen through the dark before it cracked into dazzling bloom.I had never been so close to fireworks before.  Each explosion reverberated deep within my chest, the shockwave travelling up my ribs to rattle my teeth. It occured to me as they sailed overhead, that if one were to misfire — reach its apex and fall without bursting — it would land right on my head, incorporating my unfortunate brains into its display of light.This closeness to death felt fitting for the new decade. With each passing day, I collect from the airwaves more evidence of our approaching doom. It creeps closer with every missive about the warming earth, the reckless politicians on the brink of world war, the specter of a devastating worldwide epidemic. It moves with determination as immense as a melting glacier, and despite our protestations, we seem as powerless to stop its slide into the dark ocean waters. And even if the eschaton of our world is far in the future, my personal midnight still slithers nearer with every chorus of Auld Lang Syne.But no wayward rocket found its way into my lap. Instead, for a brief moment, there was nothing in the world that mattered except the circles of fire that painted the sky. As the trails spread out from each concussion, I felt as if I was being pulled upwards toward them, so that I too was far above the city, among all that darkness and all those spirals of light.As we made our way back to the edge of the park, I marvelled at how these thousands glided past one another with no friction. There were no traffic lights, no cops, no signs to direct the people. But still, we flowed past each other, taking paths as suggestions, erratically but surely surging towards the exits. I entered into the lives of strangers and left them the next instant. A kid had broken his toy flashlight. A couple argued about which rideshare service to take. A man shoved by, talking intently into his phone. How did we appear to them, our little trio of foreigners?Then we were out of the milling crowd and onto Beacon Hill, and suddenly it was empty and quiet.",
            "content_html": "<p>My sister and her boyfriend visited me over New Year’s. On the day of the eve, after having our fill of window shopping at Newbury Street, we decided on a whim to go see a movie. In the darkness of the theater, we whiled away the afternoon alongside similarly bored Bostonians, and by the time we left the theater at seven, the sky too had darkened to an inky black.</p><p>“Do you want to go see the fireworks in the park?” she asked me, proposing yet another unplanned activity. I hadn’t even known that such festivities were taking place, much less at this early hour. I suppose it takes someone from out of town to recognize all the things that occur in your own city. (It’s strange how I feel that it’s my city, though I’ve lived here for less than a year. I attribute it to experiencing the city on foot, feeling each crack in the pavement rather than gliding high over the roads in a car.)</p><p>The website listed the event location cryptically only as “The Ballpark”. I vaguely recalled having wandered past a baseball field in a post- all-you-can-eat-sushi delirium, but had no idea how I would make my way back to it. We decided that the best course of action was to follow the largest crowd of people, trusting that they would take us eventually to the right place.</p><p>Our faith was misguided though, as the crowd took us instead to the Frog Pond, which in winter is repurposed into a skating rink (I do wonder what becomes of the frogs. Are they transported to a warm and safe place, perhaps close to where the ducks of Central Park are kept? Or do they stare up with crystalline eyes at the blades that pass over their faces?). I had suggested that we go skating earlier in the day, but passing by we saw that the rink was packed, children and adults alike skating round and round counterclockwise, uptempo pop music blaring out from elevated speakers. Watching their fishlike schooling, we lost our appetite for winter sports.</p><p>“Kevin’s a terrible skater anyways,” my sister told me, “We went once last year and he spent most of the time on his ass. Then someone fell in the rink and dislocated his shoulder, and he almost puked right there on the ice.”</p><p>She further described the twisted limb with a clinician’s fascinated glee. His face paled at the traumatic memory.</p><p>But now the rink had been cleared out for some sort of skating show. Instead of summery pop, the speakers were playing a crackly rendition of Tchaikovsky’s Nutcracker. We tried to shoulder our way through the crowd to get a look, but they had planned in advance and were dug in too deeply to move. (Plus, it’s bad form to shove children who barely come up to your elbow.)</p><p>“Look,” said my sister, who had walked out in front of us, “We can get a pretty good view from up here.”</p><p>She was on top of a slight incline that let us peek over the tops of rule-abiding heads and into a corner of the rink. Occasionally, a sequined arm would flash into view, or the shadow of a ponytail would splash across the floodlights when the figure skater leapt into the air. The crowd was strangely quiet, enraptured by the lone woman who traced erratic loops across the ice, like a single flake of snow twirling through frigid air.</p><p>Joining another stream of people, we found ourselves swept to the base of the Soldiers and Sailors Monument. In the darkness, its skyward column seemed sinister, the bronze faces on its side cold and inscrutable. As if in rebellion, teenagers had clambered atop the marble, laughing to each other and sipping from opaque bottles. For a second I felt the urge to join them, to take the sacred stone as my own; after all, it was to be a new decade in a few hours, and in that moment all altars to the past seemed foolish.</p><p>Instead I joined my sister and Kevin on the grassy hillside. She had located the Ballpark, whose usual fluorescence had been extinguished for the coming show. Couples spread picnic baskets on the frozen ground, not bothering to disguise their bottles of champagne. Strollers were parked sideways as to not plummet down the incline towards the incoming decade.</p><p>When the fireworks began I was startled by our proximity. We were close enough to hear the muted thumps as each rocket launched out of its tube, whistling unseen through the dark before it cracked into dazzling bloom.</p><p>I had never been so close to fireworks before.  Each explosion reverberated deep within my chest, the shockwave travelling up my ribs to rattle my teeth. It occured to me as they sailed overhead, that if one were to misfire — reach its apex and fall without bursting — it would land right on my head, incorporating my unfortunate brains into its display of light.</p><p>This closeness to death felt fitting for the new decade. With each passing day, I collect from the airwaves more evidence of our approaching doom. It creeps closer with every missive about the warming earth, the reckless politicians on the brink of world war, the specter of a devastating worldwide epidemic. It moves with determination as immense as a melting glacier, and despite our protestations, we seem as powerless to stop its slide into the dark ocean waters. And even if the eschaton of our world is far in the future, my personal midnight still slithers nearer with every chorus of Auld Lang Syne.</p><p>But no wayward rocket found its way into my lap. Instead, for a brief moment, there was nothing in the world that mattered except the circles of fire that painted the sky. As the trails spread out from each concussion, I felt as if I was being pulled upwards toward them, so that I too was far above the city, among all that darkness and all those spirals of light.</p><p>As we made our way back to the edge of the park, I marvelled at how these thousands glided past one another with no friction. There were no traffic lights, no cops, no signs to direct the people. But still, we flowed past each other, taking paths as suggestions, erratically but surely surging towards the exits. I entered into the lives of strangers and left them the next instant. A kid had broken his toy flashlight. A couple argued about which rideshare service to take. A man shoved by, talking intently into his phone. How did we appear to them, our little trio of foreigners?</p><p>Then we were out of the milling crowd and onto Beacon Hill, and suddenly it was empty and quiet.</p>",
            "url": "http://localhost:4000/2020/01/23/fireworks",
            
            
            
            
            
            "date_published": "2020-01-23T05:00:00+00:00",
            "date_modified": "2020-01-23T05:00:00+00:00",
            
                "author":  {
                "name": "Christopher Lin",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "http://localhost:4000/2020/01/12/doctor",
            "title": "The Doctor With a Thousand Faces",
            "summary": null,
            "content_text": "The basement of the Lamont Library at Harvard is a dismal place. I always imagined the facilities of the nation’s most prestigious university to be pristine, state-of-the-art monuments to human advancement. But like so many things in the academic world, the reality is filled with seventies wood-paneled furniture, black dust, and the accumulated residue of students’ tears. Along the walls squat wooden cubicles, pale yellow finish decayed to grey from scratches that lacerate every surface. To the credit of Harvard students, I have thus far found not a single phallus etched into the soft wood, though the initials of students long gone stare back at me from the walls.This is the place I have chosen to work on my medical school applications. When I have unpleasant work to do, I am drawn to the aura of stress and oppressive silence found in these academic torture chambers. I take comforting schadenfreude in the harried faces of hung-over undergrads trying to cram for exams. The more studious pupils absorbed in textbooks and 24/7 lo fi hip hop streams provide accountability when my fingers inevitably lead me to Reddit or Facebook.Moreover, I have come to realize that the feeling I seek amidst centuries old stacks of Harper’s Magazine is a lost sense of solidarity. It is a feeling that I can now only simulate; the reality is that I no longer share very much at all with these students. I no longer have exams, I no longer read textbooks, I no longer go to lectures. I go to work each day and then come home to an apartment populated not by friends but by acquaintances. I earn money and with it have taken on the miserable tedium of budgeting. Students are characters in a linear story that moves them ever in the direction of a bright postgraduate future, and I am only part of the backdrop.Indeed, the student’s life is one of narrative. College has all the makings of a traditional story: the wide-eyed beginning of freshman year, disillusionment and despair in the middle, then the fundamental growth of character leading up to the cathartic denouement of graduation. Or at least, that’s the story that a four-year program tries to formulate, and based on countless graduation Facebook posts, it is one that many students want to tell the world.But after graduating, this facade of story is harder to believe in. Such linearity becomes lost in the regular grind of a 40 hour work week; the weekdays blend one into one another, and the weekend stretches bleakly in its open possibility. Perhaps this is why travel becomes such a priority for recent graduates. A trip, with its discrete embarking and disembarking is easy to integrate into the stories you tell yourself.If student life is movie-like in its structure, then working life is rather more like a sitcom. There are episodic periods of tension and release, but I often feel that the overarching thread has been lost, like a show that has run a few seasons too many. I guess that says more about sitcoms than it does about life; sitcoms are by design specifically not coming-of-age stories, the point is that the character exist eternally, forever performing their hijinks even long after the show is over and the actors have died.//And yet the writing of a personal statement demands that I construct a single myth for the fragmented episodes of my life. A daunting task, but thankfully, I’m not alone in this endeavour. Like how George Lucas carefully studied the work of Joseph Campbell, I’ve developed what I call the Medical Monomyth.The Medical Monomyth goes as such: the aspiring med student has always had a deep, abiding, completely altruistic passion for helping people. Perhaps it manifested in volunteerism or raising starving animals or some other acceptably benign pursuit. They probably had a positive medical role model, most often a parent or other family member (talk about social reproduction!). From here there’s two different paths the Monomyth can follow: either they relentlessly pursued this life of service, culminating in this very personal statement, or they went astray at some point, but through some life changing medicine-adjacent experience realized that their true calling was the practice of medicine. Faced with their GPA, test scores, and absolutely pure beneficence of spirit, an admissions committee has no choice but to admit them.Searching for example personal statements, I stumbled upon a particularly saccharine essay held up as a paragon of excellence by a pre-med prep company. It narrates in masturbatory detail an episode in which the writer holds the hand of a young homeless child who sheds tears of gratitude for the home the writer is helping to build. This singular experience, stemming from the writer’s supernova-like outpouring of altruism convinces them that they were destined to become a doctor from the moment of birth, and that all the various branching forks of their life converged upon the inevitable future reception of their long white coat.Perhaps I am only so cynical and dismissive of stories like this because I fear my own powers of self-mythologization (as ironic as that might be, considering that you’re reading this on a personal blog). It’s inevitable that the stories I tell about myself will be in some ways untrue; I will sharpen my strengths, smooth over my faults, leave out the unruly textures that constitute lived experience. And horrifyingly, I know that if I repeat these to myself enough times, I’ll believe them.The truth is that the varying paths of my life did not converge upon medicine. I could easily have become a programmer, a musician, a (you laugh) writer, and indeed at various times I felt convinced that those would be my future. Medicine was a choice among equals, a fork in the road like any other.So what will become of those paths that I did not take, if I refuse to acknowledge their existence? I can already see the weeds sprouting between pavement crumbling slowly to gravel. In my future lie eighty to one-hundred hour work weeks, which will leave little time for garden tending.//It has been unseasonably warm these first few weeks of January, or at least that’s what I’ve been told. I was promised that the temperatures would drop into the negatives over the winter, and I wait eagerly for that, if for no reason other than to have a complaint for my southern friends. But yet the South seems to have followed me to New England, coaxing joggers and dog-walkers back onto the streets. It will reach nearly seventy degrees in the afternoon, a reckless insurrection against the domination of Winter. I can hear the grumble of skateboard wheels against pavement. There’s an ice cream shop in Harvard Square that I had meant to try during the summer, but calorie-consciousness and then cooler weather kept me from its doors.This is all to say, it’s far too nice out to choose the inside of a library.",
            "content_html": "<p>The basement of the Lamont Library at Harvard is a dismal place. I always imagined the facilities of the nation’s most prestigious university to be pristine, state-of-the-art monuments to human advancement. But like so many things in the academic world, the reality is filled with seventies wood-paneled furniture, black dust, and the accumulated residue of students’ tears. Along the walls squat wooden cubicles, pale yellow finish decayed to grey from scratches that lacerate every surface. To the credit of Harvard students, I have thus far found not a single phallus etched into the soft wood, though the initials of students long gone stare back at me from the walls.</p><p>This is the place I have chosen to work on my medical school applications. When I have unpleasant work to do, I am drawn to the aura of stress and oppressive silence found in these academic torture chambers. I take comforting schadenfreude in the harried faces of hung-over undergrads trying to cram for exams. The more studious pupils absorbed in textbooks and 24/7 lo fi hip hop streams provide accountability when my fingers inevitably lead me to Reddit or Facebook.</p><p>Moreover, I have come to realize that the feeling I seek amidst centuries old stacks of Harper’s Magazine is a lost sense of solidarity. It is a feeling that I can now only simulate; the reality is that I no longer share very much at all with these students. I no longer have exams, I no longer read textbooks, I no longer go to lectures. I go to work each day and then come home to an apartment populated not by friends but by acquaintances. I earn money and with it have taken on the miserable tedium of budgeting. Students are characters in a linear story that moves them ever in the direction of a bright postgraduate future, and I am only part of the backdrop.</p><p>Indeed, the student’s life is one of narrative. College has all the makings of a traditional story: the wide-eyed beginning of freshman year, disillusionment and despair in the middle, then the fundamental growth of character leading up to the cathartic denouement of graduation. Or at least, that’s the story that a four-year program tries to formulate, and based on countless graduation Facebook posts, it is one that many students want to tell the world.</p><p>But after graduating, this facade of story is harder to believe in. Such linearity becomes lost in the regular grind of a 40 hour work week; the weekdays blend one into one another, and the weekend stretches bleakly in its open possibility. Perhaps this is why travel becomes such a priority for recent graduates. A trip, with its discrete embarking and disembarking is easy to integrate into the stories you tell yourself.</p><p>If student life is movie-like in its structure, then working life is rather more like a sitcom. There are episodic periods of tension and release, but I often feel that the overarching thread has been lost, like a show that has run a few seasons too many. I guess that says more about sitcoms than it does about life; sitcoms are by design specifically not coming-of-age stories, the point is that the character exist eternally, forever performing their hijinks even long after the show is over and the actors have died.</p><p>//</p><p>And yet the writing of a personal statement demands that I construct a single myth for the fragmented episodes of my life. A daunting task, but thankfully, I’m not alone in this endeavour. Like how George Lucas carefully studied the work of Joseph Campbell, I’ve developed what I call the Medical Monomyth.</p><p>The Medical Monomyth goes as such: the aspiring med student has always had a deep, abiding, completely altruistic passion for helping people. Perhaps it manifested in volunteerism or raising starving animals or some other acceptably benign pursuit. They probably had a positive medical role model, most often a parent or other family member (talk about social reproduction!). From here there’s two different paths the Monomyth can follow: either they relentlessly pursued this life of service, culminating in this very personal statement, or they went astray at some point, but through some life changing medicine-adjacent experience realized that their true calling was the practice of medicine. Faced with their GPA, test scores, and absolutely pure beneficence of spirit, an admissions committee has no choice but to admit them.</p><p>Searching for example personal statements, I stumbled upon a particularly saccharine essay held up as a paragon of excellence by a pre-med prep company. It narrates in masturbatory detail an episode in which the writer holds the hand of a young homeless child who sheds tears of gratitude for the home the writer is helping to build. This singular experience, stemming from the writer’s supernova-like outpouring of altruism convinces them that they were destined to become a doctor from the moment of birth, and that all the various branching forks of their life converged upon the inevitable future reception of their long white coat.</p><p>Perhaps I am only so cynical and dismissive of stories like this because I fear my own powers of self-mythologization (as ironic as that might be, considering that you’re reading this on a personal blog). It’s inevitable that the stories I tell about myself will be in some ways untrue; I will sharpen my strengths, smooth over my faults, leave out the unruly textures that constitute lived experience. And horrifyingly, I know that if I repeat these to myself enough times, I’ll believe them.</p><p>The truth is that the varying paths of my life did not converge upon medicine. I could easily have become a programmer, a musician, a (you laugh) writer, and indeed at various times I felt convinced that those would be my future. Medicine was a choice among equals, a fork in the road like any other.</p><p>So what will become of those paths that I did not take, if I refuse to acknowledge their existence? I can already see the weeds sprouting between pavement crumbling slowly to gravel. In my future lie eighty to one-hundred hour work weeks, which will leave little time for garden tending.</p><p>//</p><p>It has been unseasonably warm these first few weeks of January, or at least that’s what I’ve been told. I was promised that the temperatures would drop into the negatives over the winter, and I wait eagerly for that, if for no reason other than to have a complaint for my southern friends. But yet the South seems to have followed me to New England, coaxing joggers and dog-walkers back onto the streets. It will reach nearly seventy degrees in the afternoon, a reckless insurrection against the domination of Winter. I can hear the grumble of skateboard wheels against pavement. There’s an ice cream shop in Harvard Square that I had meant to try during the summer, but calorie-consciousness and then cooler weather kept me from its doors.</p><p>This is all to say, it’s far too nice out to choose the inside of a library.</p>",
            "url": "http://localhost:4000/2020/01/12/doctor",
            
            
            
            
            
            "date_published": "2020-01-12T05:00:00+00:00",
            "date_modified": "2020-01-12T05:00:00+00:00",
            
                "author":  {
                "name": "Christopher Lin",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "http://localhost:4000/2019/12/23/film-and-memory",
            "title": "On Film Photography",
            "summary": null,
            "content_text": "When I traveled back to my home in Alabama this past Thanksgiving, I discovered in my old room among the detritus of childhood, several canisters of negative film. Popping off the lids and giving them a cursory examination, I saw that they were the few rolls of film that I had shot during the first two years of college, before I gave up photography for the remainder of school. I did not, however, remember exactly what photographs they contained.Since childhood I had an affinity for cameras — in elementary school I spent long afternoons and evenings unaware of loneliness, making stop motion videos with Lego bricks and our family’s point-and-shoot digital camera. During vacations, I would make it my job to document the highway landscapes we drove past, the hotels we slept in, and the museums we explored (I was never too interested in taking photos of people, much to my parents’ chagrin). My eyes lingered longingly on the cameras displayed in the electronics section of Costco during our family’s weekly grocery trips. But a high quality camera always seemed prohibitively expensive and out of reach.That is, until high school, when a photography enthusiast in my computer science class informed me that film photography was not just a dead art practiced by aging weirdos. In fact, the quality of images produced by 35mm film could only be matched by full-frame DSLRs, which were (and still are) extravagantly beyond my budget. What was more, top-end vintage gear could be easily picked up in thrift stores or online for a fraction of the cost of new cameras.I resolved to get a film camera, and I convinced my somewhat skeptical parents to buy me a Canon A1 off of Craigslist as a birthday gift. I spent that waning year of high shooting as many rolls of film as I could. My local photo lab would develop film for $2 a roll, and I jury-rigged a rudimentary DIY film scanning set up with a desk lamp, a white plastic bag, and a digital point-and-shoot. I fell in love with the graininess, the color shifts and general imperfections inherent in film — a photograph taken on film immediately looks like an object of art rather than a documentation of reality.But like so many past hobbies of mine, my passion was fated to eventually fade away. This time, it was not due solely to laziness or boredom, the culprits of my other abandoned pursuits, but instead was largely due to the transition to college.I had envisioned my college to be a photographic heaven. Under the gothic archways, surrounded by intellectual, like minded students, I expected there to be no shortage of things to photograph. But on the contrary, I found an utter lack of compelling subjects. There was not a square inch that was safe from the hungry smartphone cameras of campus-bound students; images of every building, every room, every tree and every flower proliferated on Instagram and Facebook until the entire campus was a single visual cliche. I felt foolish toting my bulky SLR around campus in order to snap pictures of the same archways and gardens crowded by camera-happy students and tourists.So my camera sat untouched on my desk, or sometimes was even relegated to a closet shelf, coming out of hibernation only for special events: a visit to the state fair, a trip to Atlanta with my family, a visit to the school gardens before that too became passe for me. But the specific shots, the discrete slices of time, memory and emotion were unknown to me.It would perhaps be not too far a stretch to say that I had never known these moments even as I brought the viewfinder up to my eye. Remembrance was of little importance to me in those first two years of school. I had developed these rolls, but never made the time to scan them in the library. There was some part of me that still loved the physical act of focusing the lens and feeling the tactile click of the shutter, but once the moment passed, these documents of the past became unimportant to me. I was determined to rush headlong into the future.Then of course, as befalls all those who rush headlong, I arrived at my destination. Friends disappeared, courses of studies changed, relationships ended – all natural catastrophes, the cyclic sweeping of flame through an evergreen forest. But nevertheless, they were catastrophes that I was unwilling and unable to prepare for.And after that, I felt no desire to attempt to revisit the faces of people who had passed from my life, or to attempt to conjure up old feelings that were now locked in a past I could no longer access. What was the point, other than a sense of masochism, to revisit the haunted halls of the past? It was better to stoically deny those ghosts any power. So the film sat, developed but unknown, in the back of a drawer at home, out of sight and out of mind.//Henri Bergson conceived of time as a strip of film passing between two reels. In his view, the passage of time is produced by cumulative difference: Monday must be different from Sunday, but Tuesday must be different from both Sunday and Monday, Wednesday must differ from Tuesday in addition to Monday and Sunday, and so on and so forth.Thus, the uptake reel grows larger and larger as each moment passes before the snap of the shutter. Each moment contains inscribed within it every previous moment in history; a walk in the garden remembers all previous walks in the garden — and not just your walks, but all walks from all people, all dogs, all ducks, all children not yet able to walk being pushed in strollers by their parents — and not just the walks, but sunsets and sunrises, the summer heat, the dry autumn days, the rare winter cold snaps that freeze the fountains into solid blocks of ice, encasing within them hapless bacteria and protists who remember not so long ago the first aggregates of algae being formed on a hot Earth…What then becomes of the present? Does it get more and more bloated with each passing moment? Ghosts of the past fade but refuse to disappear. Today is forever chained to comparison with days past. Is it better than yesterday: brighter, louder, more joyful, more vital? Or have you passed the inflection point of your happiness graph? One thing is for certain: those things you once had can never be recreated.We often think of photographs as faithful recreations of the past, but they are nothing but crude approximations. The colors are off, the horizon is warped, the edge of your face is blurry with movement. The photograph was doomed from the moment it was taken; it is something static, but there was no point in time when the real world stood still. Unable to capture or to recreate, remembrance is a doomed project from the start.//Since moving to Boston, I have taken up analog photography once more. The city is an endless stream of interesting subjects; just walk down the street shooting from the hip and you’re bound to get a few good shots. But some of my most fruitful photographs came not from the rushing of cars and faces, but from a Sunday hiking trip I took with friends from work.We drove in the morning to Mt. Monadnock in New Hampshire, about an hour and a half from the city. The trees were fiery red and orange, and I cursed my lack of foresight for being only able to capture them on black and white film. The trail we hiked was short but very steep; in other words, a monstrous challenge for someone who had not hiked anything more strenuous than gravel-paved Alabama foothills. The previous night’s rain ran in rivulets down our trail, and the rocks were cold and slick. My trusty A1 had survived almost 35 years of wear, but I feared for its safety as it, bouncing on its strap around my neck, sometimes skidded along the enormous boulders we clambered across. After embarrassingly many rests and water breaks, we reached the summit. Save for the hikers who crowded there gulping water and eating granola bars, the top of the mountain was completely barren. Not even insects crawled along the gray rocks.At the time, I thought that it must be that the climate there was so inhospitable, so cold and windy that not even shrubs could find traction among the rocks. But after we had hiked down into the warm embrace of cell service, I learned that the environment was perfectly hospitable to trees; in fact the summit was once lush with flora. In the early 1800s, settlers set fire to the mountain hoping the blaze would create pastures for their sheep. Only a decade later, suspecting that the wolves that terrorized their herds had made dens in the uprooted trees left by the blaze, they once again ignited the mountain, reducing what was left of vegetation to ash, driving away the wolves along with their dreams of soft green pastures.In middle school life sciences, we were taught about the stages of ecological succession. After a catastrophe such as a wildfire or volcano, the first to venture out onto the alien earth are bacteria, who slowly wear away at the bare minerals. Next come algae and moss, against all odds turning lifeless rock into dirt. A bird, on its way home, deposits a seed into this dirt, and out springs a low shrub, which becomes a multitude of shrubs, and with them come insects, rodents, more birds. Finally saplings arrive, which become red spruce trees, towering waxy-needled in the snow.And yet, two hundred years after the blaze, after countless elections, civil wars, and brushes with atomic annihilation, not even moss had dared to creep across the rock of Monadnock. What does Monadnock remember so vividly, that its trauma centuries past still haunts it?From the summit, my friend tried to point out to me the skyline of Boston. I smiled and nodded, but no matter how hard I squinted, I couldn’t make out its angular forms amongst the blowing of wind, the sloping of mountainsides, the wreathing of mists, the coloring of trees. Then it started to hail.//Say you wind up the film advance, meter carefully (for the shadows, not the highlights!), hold your breath and work up the courage to press the shutter release. How does the scene in framed in your viewfinder (the forested base of a mountain perhaps) become the digital ephemera to be launched into the stratosphere of your (barely followed) Instagram page?The plastic film stock is coated in a layer of silver halide ions. When the shutter opens its eye, photons stream in and strike the ions, exciting their electrons to higher orbitals. These areas of excitation join together to form metastable networks, transforming the continuous energies of the Outside into discrete areas of chemistry.The shutter closes, and these metastable networks are sealed away into darkness. To the naked eye (with the aid of a safelight perhaps), the film would look no different than it had before being exposed. But beneath the placid silver lake there is a great teeming of ghosts – electrons spinning and leaping to the echoes of past intensities.These ghosts are fixed in place by the addition of developer fluid. A mild reducing agent, developer converts silver ions to their stable form. The more excited a molecule, the faster it converts; the areas of film exposed to brighter light are transfigured into silver, while areas of darkness remain in their ionic form. Thus, the film has become immune to the light of the present.But yet the haunting is not over; even now no image is formed on the blank metallic face of the film. To exorcise these ghosts requires an act of selective forgetting. The film is finally submerged into a fixer solution, which washes away the silver that remains in ionic form. The lowest intensities of light that once existed in your viewfinder vanish without a trace. Funguses peeking out from the corners of leaves, the half decomposed bones of squirrels buried in loam, the insects in shadow but nonetheless vital all swirling down your sink…And what is left is a negative image, a chemically rendered graph of the events that you, through your wielding of developer solution, chose to remain. If remembrance is the creation of images, then to remember is to forget, to create a history of the world as you wish to know it.//Gilles Deleuze modified Bergson’s notion of time so that the past does not exist hierarchically inscribed within moments. Time is not in the image of film passing between reels: all moments of the past coexist in virtuality, side by side as rolls of film sitting in the back of a drawer. All of the past (including what in the “future” will be regarded as “past”) has always-ever existed as the virtual; the present is simply the physical actualization of a subset of the virtual past.In this scheme, the present is unchained from comparison. Difference in the virtual plane is qualitative, not quantitative. The difference between moments in time is not a difference-in-degree, but instead a difference-in-kind; moments simply cannot be held up for comparison. Happiness cannot have an inflection point, because happiness simply cannot be graphed. Today is no better nor worse than yesterday, it is only different.Remembering, according to Deleuze, becomes an active, productive process that actualizes the virtual past into the physical present. Physical changes are produced in neurons, chemical changes occur in silver halide, the rock of the mountaintop remains stubbornly, physically and chemically inhospitable to life. Remembering is not living in the past; on the contrary, remembering is creating the present. To remember is to express an agency in selecting which moments of the past contribute to the world.//Lately I find that I am often immersed in memory. Perhaps this is due to my attempts to become a regular writer. Or maybe it’s because getting from one place to another in Boston often requires long walks where your mind is free to wander into places it usually avoids. The acrid smell of bus exhaust pulls me into childhood summers in Taipei. The hush of the first snow reminds me of the rare times when class was cancelled for winter weather. Strangers look like people I’ll never see again.Sometimes I’m troubled by how flawed my memory seems. What was it that I had for lunch yesterday? Who was the first person to greet me in the morning? At night, at the edge of sleep, I’m gripped by a solipsistic terror that I never existed until the present moment. What guarantee is there that my personal history is not just a fiction, that the people I remember loving are not just a figment of imagination? Thankfully, these Cartesian fears always evaporate with the chirp of my alarm clock.In the basement of Lamont Library at Harvard, there’s two film scanners that always seem to be unused. A few days after arriving back in Boston, I had an overpriced coffee in Harvard Square with a friend, then headed to Lamont to finally scan my old negatives.Scanning negatives is more an art than a science. You’d think that there must be some way of calibrating the scanner’s sensor to extract the true colors of the film. But despite endless flame wars on photography forums, no one can seem to agree upon what the true colors of a given film stock really are. Ultimately, it’s a judgement call. It’s up to you whether you want to remember things as being slightly bluer or slightly redder.One of the best photos in those rolls was of my ex-girlfriend. It’s mid-October, and we’re at the Carolina State Fair. The sun has already set, so the only sources of light are garish blobs of color from the rickety rides and greasy food stands. She’s looking slightly behind and to the left of the lens, caught halfway in a smile. The cast of the lights make her hair appear redder than it ever really was.I sent the photo to her, and she told me that she doesn’t like how she looks in it. But she assures me that nevertheless, she thinks that it’s a cool photo.",
            "content_html": "<p>When I traveled back to my home in Alabama this past Thanksgiving, I discovered in my old room among the detritus of childhood, several canisters of negative film. Popping off the lids and giving them a cursory examination, I saw that they were the few rolls of film that I had shot during the first two years of college, before I gave up photography for the remainder of school. I did not, however, remember exactly what photographs they contained.</p><p>Since childhood I had an affinity for cameras — in elementary school I spent long afternoons and evenings unaware of loneliness, making stop motion videos with Lego bricks and our family’s point-and-shoot digital camera. During vacations, I would make it my job to document the highway landscapes we drove past, the hotels we slept in, and the museums we explored (I was never too interested in taking photos of people, much to my parents’ chagrin). My eyes lingered longingly on the cameras displayed in the electronics section of Costco during our family’s weekly grocery trips. But a high quality camera always seemed prohibitively expensive and out of reach.</p><p>That is, until high school, when a photography enthusiast in my computer science class informed me that film photography was not just a dead art practiced by aging weirdos. In fact, the quality of images produced by 35mm film could only be matched by full-frame DSLRs, which were (and still are) extravagantly beyond my budget. What was more, top-end vintage gear could be easily picked up in thrift stores or online for a fraction of the cost of new cameras.</p><p>I resolved to get a film camera, and I convinced my somewhat skeptical parents to buy me a Canon A1 off of Craigslist as a birthday gift. I spent that waning year of high shooting as many rolls of film as I could. My local photo lab would develop film for $2 a roll, and I jury-rigged a rudimentary DIY film scanning set up with a desk lamp, a white plastic bag, and a digital point-and-shoot. I fell in love with the graininess, the color shifts and general imperfections inherent in film — a photograph taken on film immediately looks like an object of art rather than a documentation of reality.</p><p>But like so many past hobbies of mine, my passion was fated to eventually fade away. This time, it was not due solely to laziness or boredom, the culprits of my other abandoned pursuits, but instead was largely due to the transition to college.</p><p>I had envisioned my college to be a photographic heaven. Under the gothic archways, surrounded by intellectual, like minded students, I expected there to be no shortage of things to photograph. But on the contrary, I found an utter lack of compelling subjects. There was not a square inch that was safe from the hungry smartphone cameras of campus-bound students; images of every building, every room, every tree and every flower proliferated on Instagram and Facebook until the entire campus was a single visual cliche. I felt foolish toting my bulky SLR around campus in order to snap pictures of the same archways and gardens crowded by camera-happy students and tourists.</p><p>So my camera sat untouched on my desk, or sometimes was even relegated to a closet shelf, coming out of hibernation only for special events: a visit to the state fair, a trip to Atlanta with my family, a visit to the school gardens before that too became passe for me. But the specific shots, the discrete slices of time, memory and emotion were unknown to me.</p><p>It would perhaps be not too far a stretch to say that I had never known these moments even as I brought the viewfinder up to my eye. Remembrance was of little importance to me in those first two years of school. I had developed these rolls, but never made the time to scan them in the library. There was some part of me that still loved the physical act of focusing the lens and feeling the tactile click of the shutter, but once the moment passed, these documents of the past became unimportant to me. I was determined to rush headlong into the future.</p><p>Then of course, as befalls all those who rush headlong, I arrived at my destination. Friends disappeared, courses of studies changed, relationships ended – all natural catastrophes, the cyclic sweeping of flame through an evergreen forest. But nevertheless, they were catastrophes that I was unwilling and unable to prepare for.</p><p>And after that, I felt no desire to attempt to revisit the faces of people who had passed from my life, or to attempt to conjure up old feelings that were now locked in a past I could no longer access. What was the point, other than a sense of masochism, to revisit the haunted halls of the past? It was better to stoically deny those ghosts any power. So the film sat, developed but unknown, in the back of a drawer at home, out of sight and out of mind.</p><p>//</p><p>Henri Bergson conceived of time as a strip of film passing between two reels. In his view, the passage of time is produced by cumulative difference: Monday must be different from Sunday, but Tuesday must be different from both Sunday and Monday, Wednesday must differ from Tuesday in addition to Monday and Sunday, and so on and so forth.</p><p>Thus, the uptake reel grows larger and larger as each moment passes before the snap of the shutter. Each moment contains inscribed within it every previous moment in history; a walk in the garden remembers all previous walks in the garden — and not just your walks, but all walks from all people, all dogs, all ducks, all children not yet able to walk being pushed in strollers by their parents — and not just the walks, but sunsets and sunrises, the summer heat, the dry autumn days, the rare winter cold snaps that freeze the fountains into solid blocks of ice, encasing within them hapless bacteria and protists who remember not so long ago the first aggregates of algae being formed on a hot Earth…</p><p>What then becomes of the present? Does it get more and more bloated with each passing moment? Ghosts of the past fade but refuse to disappear. Today is forever chained to comparison with days past. Is it better than yesterday: brighter, louder, more joyful, more vital? Or have you passed the inflection point of your happiness graph? One thing is for certain: those things you once had can never be recreated.</p><p>We often think of photographs as faithful recreations of the past, but they are nothing but crude approximations. The colors are off, the horizon is warped, the edge of your face is blurry with movement. The photograph was doomed from the moment it was taken; it is something static, but there was no point in time when the real world stood still. Unable to capture or to recreate, remembrance is a doomed project from the start.</p><p>//</p><p>Since moving to Boston, I have taken up analog photography once more. The city is an endless stream of interesting subjects; just walk down the street shooting from the hip and you’re bound to get a few good shots. But some of my most fruitful photographs came not from the rushing of cars and faces, but from a Sunday hiking trip I took with friends from work.</p><p>We drove in the morning to Mt. Monadnock in New Hampshire, about an hour and a half from the city. The trees were fiery red and orange, and I cursed my lack of foresight for being only able to capture them on black and white film. The trail we hiked was short but very steep; in other words, a monstrous challenge for someone who had not hiked anything more strenuous than gravel-paved Alabama foothills. The previous night’s rain ran in rivulets down our trail, and the rocks were cold and slick. My trusty A1 had survived almost 35 years of wear, but I feared for its safety as it, bouncing on its strap around my neck, sometimes skidded along the enormous boulders we clambered across. After embarrassingly many rests and water breaks, we reached the summit. Save for the hikers who crowded there gulping water and eating granola bars, the top of the mountain was completely barren. Not even insects crawled along the gray rocks.</p><p>At the time, I thought that it must be that the climate there was so inhospitable, so cold and windy that not even shrubs could find traction among the rocks. But after we had hiked down into the warm embrace of cell service, I learned that the environment was perfectly hospitable to trees; in fact the summit was once lush with flora. In the early 1800s, settlers set fire to the mountain hoping the blaze would create pastures for their sheep. Only a decade later, suspecting that the wolves that terrorized their herds had made dens in the uprooted trees left by the blaze, they once again ignited the mountain, reducing what was left of vegetation to ash, driving away the wolves along with their dreams of soft green pastures.</p><p>In middle school life sciences, we were taught about the stages of ecological succession. After a catastrophe such as a wildfire or volcano, the first to venture out onto the alien earth are bacteria, who slowly wear away at the bare minerals. Next come algae and moss, against all odds turning lifeless rock into dirt. A bird, on its way home, deposits a seed into this dirt, and out springs a low shrub, which becomes a multitude of shrubs, and with them come insects, rodents, more birds. Finally saplings arrive, which become red spruce trees, towering waxy-needled in the snow.</p><p>And yet, two hundred years after the blaze, after countless elections, civil wars, and brushes with atomic annihilation, not even moss had dared to creep across the rock of Monadnock. What does Monadnock remember so vividly, that its trauma centuries past still haunts it?</p><p>From the summit, my friend tried to point out to me the skyline of Boston. I smiled and nodded, but no matter how hard I squinted, I couldn’t make out its angular forms amongst the blowing of wind, the sloping of mountainsides, the wreathing of mists, the coloring of trees. Then it started to hail.</p><p>//</p><p>Say you wind up the film advance, meter carefully (for the shadows, not the highlights!), hold your breath and work up the courage to press the shutter release. How does the scene in framed in your viewfinder (the forested base of a mountain perhaps) become the digital ephemera to be launched into the stratosphere of your (barely followed) Instagram page?</p><p>The plastic film stock is coated in a layer of silver halide ions. When the shutter opens its eye, photons stream in and strike the ions, exciting their electrons to higher orbitals. These areas of excitation join together to form metastable networks, transforming the continuous energies of the Outside into discrete areas of chemistry.</p><p>The shutter closes, and these metastable networks are sealed away into darkness. To the naked eye (with the aid of a safelight perhaps), the film would look no different than it had before being exposed. But beneath the placid silver lake there is a great teeming of ghosts – electrons spinning and leaping to the echoes of past intensities.</p><p>These ghosts are fixed in place by the addition of developer fluid. A mild reducing agent, developer converts silver ions to their stable form. The more excited a molecule, the faster it converts; the areas of film exposed to brighter light are transfigured into silver, while areas of darkness remain in their ionic form. Thus, the film has become immune to the light of the present.</p><p>But yet the haunting is not over; even now no image is formed on the blank metallic face of the film. To exorcise these ghosts requires an act of selective forgetting. The film is finally submerged into a fixer solution, which washes away the silver that remains in ionic form. The lowest intensities of light that once existed in your viewfinder vanish without a trace. Funguses peeking out from the corners of leaves, the half decomposed bones of squirrels buried in loam, the insects in shadow but nonetheless vital all swirling down your sink…</p><p>And what is left is a negative image, a chemically rendered graph of the events that you, through your wielding of developer solution, chose to remain. If remembrance is the creation of images, then to remember is to forget, to create a history of the world as you wish to know it.</p><p>//</p><p>Gilles Deleuze modified Bergson’s notion of time so that the past does not exist hierarchically inscribed within moments. Time is not in the image of film passing between reels: all moments of the past coexist in virtuality, side by side as rolls of film sitting in the back of a drawer. All of the past (including what in the “future” will be regarded as “past”) has always-ever existed as the virtual; the present is simply the physical actualization of a subset of the virtual past.</p><p>In this scheme, the present is unchained from comparison. Difference in the virtual plane is qualitative, not quantitative. The difference between moments in time is not a difference-in-degree, but instead a difference-in-kind; moments simply cannot be held up for comparison. Happiness cannot have an inflection point, because happiness simply cannot be graphed. Today is no better nor worse than yesterday, it is only different.</p><p>Remembering, according to Deleuze, becomes an active, productive process that actualizes the virtual past into the physical present. Physical changes are produced in neurons, chemical changes occur in silver halide, the rock of the mountaintop remains stubbornly, physically and chemically inhospitable to life. Remembering is not living in the past; on the contrary, remembering is creating the present. To remember is to express an agency in selecting which moments of the past contribute to the world.</p><p>//</p><p>Lately I find that I am often immersed in memory. Perhaps this is due to my attempts to become a regular writer. Or maybe it’s because getting from one place to another in Boston often requires long walks where your mind is free to wander into places it usually avoids. The acrid smell of bus exhaust pulls me into childhood summers in Taipei. The hush of the first snow reminds me of the rare times when class was cancelled for winter weather. Strangers look like people I’ll never see again.</p><p>Sometimes I’m troubled by how flawed my memory seems. What was it that I had for lunch yesterday? Who was the first person to greet me in the morning? At night, at the edge of sleep, I’m gripped by a solipsistic terror that I never existed until the present moment. What guarantee is there that my personal history is not just a fiction, that the people I remember loving are not just a figment of imagination? Thankfully, these Cartesian fears always evaporate with the chirp of my alarm clock.</p><p>In the basement of Lamont Library at Harvard, there’s two film scanners that always seem to be unused. A few days after arriving back in Boston, I had an overpriced coffee in Harvard Square with a friend, then headed to Lamont to finally scan my old negatives.</p><p>Scanning negatives is more an art than a science. You’d think that there must be some way of calibrating the scanner’s sensor to extract the true colors of the film. But despite endless flame wars on photography forums, no one can seem to agree upon what the true colors of a given film stock really are. Ultimately, it’s a judgement call. It’s up to you whether you want to remember things as being slightly bluer or slightly redder.</p><p>One of the best photos in those rolls was of my ex-girlfriend. It’s mid-October, and we’re at the Carolina State Fair. The sun has already set, so the only sources of light are garish blobs of color from the rickety rides and greasy food stands. She’s looking slightly behind and to the left of the lens, caught halfway in a smile. The cast of the lights make her hair appear redder than it ever really was.</p><p>I sent the photo to her, and she told me that she doesn’t like how she looks in it. But she assures me that nevertheless, she thinks that it’s a cool photo.</p>",
            "url": "http://localhost:4000/2019/12/23/film-and-memory",
            
            
            
            
            
            "date_published": "2019-12-23T17:00:00+00:00",
            "date_modified": "2019-12-23T17:00:00+00:00",
            
                "author":  {
                "name": "Christopher Lin",
                "url": null,
                "avatar": null
                }
                
            
        },
    
        {
            "id": "http://localhost:4000/2019/05/24/foucaults-pendulum",
            "title": "On Foucault's Pendulum",
            "summary": null,
            "content_text": "Foucault’s Pendulum by Italian philosopher and author Umberto Eco has been on my ever-growing to-read list for quite a while. I picked up his most well known book, The Name of the Rose, from a thrift shop a few years ago based on name recognition (The Name of the Rose was featured on one of the endless lists of author-title pairings I memorized during my stint on the high school quiz bowl team). The first few chapters were almost excruciating to read; after a lengthy and seemingly irrelevant fictional foreword, we meet our main characters who  do nothing but pontificate endlessly on medieval history and Aristotelian logic. It was clear to me why someone had decided to discard it alongside ragged copies of great literary classics like Jimmy Buffett’s Tales From Margaritaville. But thankfully, I was stuck on a plane and had nothing better to do than to power through. Soon, I was completely immersed in Eco’s 14th century world of monastic intrigue, religious power struggles, and heady debates on philosophy and theology. I couldn’t get enough of it, and it launched my interest in philosophy and Serious Literary Studies (™).Now, two literature classes and a disappointingly small number of theory books later, I thought that I was ready to tackle Foucault’s Pendulum, Eco’s magnum opus (according to some people on Reddit, that is). It’s a door stopper of a book, clocking in at 623 pages, dense with untranslated Latin and French, obscure references to Renaissance history, and even more obscure references to occult traditions. It has a reputation for being borderline unreadable. “One of those books where the author tediously says next to nothing, and all the semi-litterati can’t figure out what he’s trying to say, so they conclude he must be brilliant”, rants a reviewer on Goodreads. I suspect I am precisely the semi-litterati being referred to here.Set against the political tumult of 70’s and 80’s Italy, Foucault’s Pendulum follows the misadventures of the overeducated Casaubon, who works as a sort of scholarly detective. He becomes involved in the machinations of the academic press Garamond and its vanity alter-ego, Manutius. Garamond/Manutius has discovered that occult literature (both scholarly and pseudo-scholarly) is a vast untapped market, and has decided to begin publishing a series of books dealing with the esoteric. Casaubon along with his coworkers Diotallevi and Belbo are tasked with sorting through the manuscripts and deciding which are fit for Garamond, and which will be pushed to Manutius. The trio quickly become bored of their work, and decide to create the Plan, an all encompassing conspiracy theory that links the Templars to every significant event in the Western world since the middle ages. As the trio sinks deeper into the conspiracy of their own making, their scholarly joke begins to have real life consequences.It’s quite easy to find contemporary analogues to the novel. Just replace “Templars” with “Jews” or “Deep State”, and you cover a whole slew of modern internet conspiracies. The Initiate and the Mystic have been replaced by the Youtuber and the Anonymous 4Chan Poster. Followers of these new occult traditions do not submit their work to vanity presses, but instead post them on blogs and make three-hour-long videos complete with innocuous photos of celebrities marked up with arcane symbols.This is only to be expected, as Foucault’s Pendulum is, through its exploration of those who believe in conspiracies, a projection of the epistemic trajectories of postmodernity. If there is no Absolute, no center from which to suspend the pendulum of the world, then there is no reason not to rearrange and connect knowledge in any way you so choose. “When men stop believing in God, it isn’t that they then believe in nothing: they believe in everything”, muses Casaubon. Perhaps this sense of centerless-ness is felt especially acutely in the age of the internet. Wildly different conceptions of the Absolute, whether in religion, philosophy, or political ideology, are forced to exist side by side in hyperspace. In this kind of environment, it is only natural that the breaking down of metanarratives is no longer just an exercise of academia, but an exercise of the connected masses. One can interpret the recent surge in conspiratorial thought as a reactionary force against this; the postmodern subject searches desperately for a center from which their conditions can be understood.This is not to say that conspiracy theories are benign. In Foucault’s Pendulum, the driving force of the occultists is not existential ennui but lust for power. They are focused on obtaining control of the Umbilicus Telluris, the Navel of the World, from which they can bring any government to its knees. The occultists buy wholesale into The Plan and pursue it relentlessly, with disastrous consequences for the trio of main characters. Modern conspiracy theorists likewise are focused on finding loci of power. As mentioned before, the Jews and the Deep State are common culprits, as are the Rothschilds, the Bilderberg Group, the Illuminati, Satanists, the New World Order, and of course we can’t forget the Lizard People. However, In contrast to the occultists of the novel, internet conspiracy theorists are mostly limited to the confines of cyberspace (though the Comet Ping Pong events of 2016 suggest this may be changing). And in recent years, internet conspiracies have taken a decidedly nastier bent; it seems the majority of conspiracies now are targeted towards marginalized groups rather than the elites (though again, Jews have always been a ubiquitous target). You can blame this on the sinister workings of patriarchy, racist social structures, or capital.But maybe there is a silver lining, however slim it may be. In contrast to the occultists of Foucault’s Pendulum, real-life conspiracy theorists for the most part seek not to seize power, but instead to destroy it. However malicious or misguided their identification of power centers, as a whole, the collective impulse is to destabilize and destroy power and return the world to a “freer”, more democratic state. I might be overly optimistic here, and more than a bit naive, but the common desire for democracy is perhaps something we still might believe in, a worthy Absolute that we still might hang the world from.",
            "content_html": "<p>Foucault’s Pendulum by Italian philosopher and author Umberto Eco has been on my ever-growing to-read list for quite a while. I picked up his most well known book, The Name of the Rose, from a thrift shop a few years ago based on name recognition (The Name of the Rose was featured on one of the endless lists of author-title pairings I memorized during my stint on the high school quiz bowl team). The first few chapters were almost excruciating to read; after a lengthy and seemingly irrelevant fictional foreword, we meet our main characters who  do nothing but pontificate endlessly on medieval history and Aristotelian logic. It was clear to me why someone had decided to discard it alongside ragged copies of great literary classics like Jimmy Buffett’s Tales From Margaritaville. But thankfully, I was stuck on a plane and had nothing better to do than to power through. Soon, I was completely immersed in Eco’s 14th century world of monastic intrigue, religious power struggles, and heady debates on philosophy and theology. I couldn’t get enough of it, and it launched my interest in philosophy and Serious Literary Studies (™).</p><p>Now, two literature classes and a disappointingly small number of theory books later, I thought that I was ready to tackle Foucault’s Pendulum, Eco’s magnum opus (according to some people on Reddit, that is). It’s a door stopper of a book, clocking in at 623 pages, dense with untranslated Latin and French, obscure references to Renaissance history, and even more obscure references to occult traditions. It has a reputation for being borderline unreadable. “One of those books where the author tediously says next to nothing, and all the semi-litterati can’t figure out what he’s trying to say, so they conclude he must be brilliant”, rants a reviewer on Goodreads. I suspect I am precisely the semi-litterati being referred to here.</p><p>Set against the political tumult of 70’s and 80’s Italy, Foucault’s Pendulum follows the misadventures of the overeducated Casaubon, who works as a sort of scholarly detective. He becomes involved in the machinations of the academic press Garamond and its vanity alter-ego, Manutius. Garamond/Manutius has discovered that occult literature (both scholarly and pseudo-scholarly) is a vast untapped market, and has decided to begin publishing a series of books dealing with the esoteric. Casaubon along with his coworkers Diotallevi and Belbo are tasked with sorting through the manuscripts and deciding which are fit for Garamond, and which will be pushed to Manutius. The trio quickly become bored of their work, and decide to create the Plan, an all encompassing conspiracy theory that links the Templars to every significant event in the Western world since the middle ages. As the trio sinks deeper into the conspiracy of their own making, their scholarly joke begins to have real life consequences.</p><p>It’s quite easy to find contemporary analogues to the novel. Just replace “Templars” with “Jews” or “Deep State”, and you cover a whole slew of modern internet conspiracies. The Initiate and the Mystic have been replaced by the Youtuber and the Anonymous 4Chan Poster. Followers of these new occult traditions do not submit their work to vanity presses, but instead post them on blogs and make three-hour-long videos complete with innocuous photos of celebrities marked up with arcane symbols.</p><p>This is only to be expected, as Foucault’s Pendulum is, through its exploration of those who believe in conspiracies, a projection of the epistemic trajectories of postmodernity. If there is no Absolute, no center from which to suspend the pendulum of the world, then there is no reason not to rearrange and connect knowledge in any way you so choose. “When men stop believing in God, it isn’t that they then believe in nothing: they believe in everything”, muses Casaubon. Perhaps this sense of centerless-ness is felt especially acutely in the age of the internet. Wildly different conceptions of the Absolute, whether in religion, philosophy, or political ideology, are forced to exist side by side in hyperspace. In this kind of environment, it is only natural that the breaking down of metanarratives is no longer just an exercise of academia, but an exercise of the connected masses. One can interpret the recent surge in conspiratorial thought as a reactionary force against this; the postmodern subject searches desperately for a center from which their conditions can be understood.</p><p>This is not to say that conspiracy theories are benign. In Foucault’s Pendulum, the driving force of the occultists is not existential ennui but lust for power. They are focused on obtaining control of the Umbilicus Telluris, the Navel of the World, from which they can bring any government to its knees. The occultists buy wholesale into The Plan and pursue it relentlessly, with disastrous consequences for the trio of main characters. Modern conspiracy theorists likewise are focused on finding loci of power. As mentioned before, the Jews and the Deep State are common culprits, as are the Rothschilds, the Bilderberg Group, the Illuminati, Satanists, the New World Order, and of course we can’t forget the Lizard People. However, In contrast to the occultists of the novel, internet conspiracy theorists are mostly limited to the confines of cyberspace (though the Comet Ping Pong events of 2016 suggest this may be changing). And in recent years, internet conspiracies have taken a decidedly nastier bent; it seems the majority of conspiracies now are targeted towards marginalized groups rather than the elites (though again, Jews have always been a ubiquitous target). You can blame this on the sinister workings of patriarchy, racist social structures, or capital.</p><p>But maybe there is a silver lining, however slim it may be. In contrast to the occultists of Foucault’s Pendulum, real-life conspiracy theorists for the most part seek not to seize power, but instead to destroy it. However malicious or misguided their identification of power centers, as a whole, the collective impulse is to destabilize and destroy power and return the world to a “freer”, more democratic state. I might be overly optimistic here, and more than a bit naive, but the common desire for democracy is perhaps something we still might believe in, a worthy Absolute that we still might hang the world from.</p>",
            "url": "http://localhost:4000/2019/05/24/foucaults-pendulum",
            
            
            
            "tags": ["essay","literature"],
            
            "date_published": "2019-05-24T10:11:11+00:00",
            "date_modified": "2019-05-24T10:11:11+00:00",
            
                "author":  {
                "name": "Christopher Lin",
                "url": null,
                "avatar": null
                }
                
            
        }
    
    ]
}